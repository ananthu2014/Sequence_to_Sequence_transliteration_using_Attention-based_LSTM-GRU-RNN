{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f80d3a-3567-469c-b207-8feceba7ced0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This jupyter notebook contains:\\n1. Data preprocessing\\n2. Transformer Encoder\\n3. Transformer Decoder\\n4. Training\\n5. Evaluation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This jupyter notebook contains:\n",
    "1. Data preprocessing\n",
    "2. Transformer Encoder\n",
    "3. Transformer Decoder\n",
    "4. Training\n",
    "5. Evaluation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99b25fe-a9b3-4feb-b9a9-53a355556c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18940c2f-6098-4db9-875e-40c158d37261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07989779-01c7-4951-8b8c-b7a51d73e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function to load the data'''\n",
    "def load_data(path,language_names):\n",
    "    df=pd.read_csv(path,header=None)\n",
    "    df.columns=language_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e6b9e6-e18e-47dc-9434-abc30f4c7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shastragaar</td>\n",
       "      <td>शस्त्रागार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>toned</td>\n",
       "      <td>टोंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>mutanaazaa</td>\n",
       "      <td>मुतनाज़ा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>asahmaton</td>\n",
       "      <td>असहमतों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>sulgaayin</td>\n",
       "      <td>सुलगायीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>anchuthengu</td>\n",
       "      <td>अंचुतेंगु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           English transliteration_in_hindi\n",
       "0      shastragaar               शस्त्रागार\n",
       "1          bindhya                 बिन्द्या\n",
       "2        kirankant                 किरणकांत\n",
       "3      yagyopaveet                यज्ञोपवीत\n",
       "4          ratania                  रटानिया\n",
       "...            ...                      ...\n",
       "51195        toned                     टोंड\n",
       "51196   mutanaazaa                 मुतनाज़ा\n",
       "51197    asahmaton                  असहमतों\n",
       "51198    sulgaayin                 सुलगायीं\n",
       "51199  anchuthengu                अंचुतेंगु\n",
       "\n",
       "[51200 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Here,basically,the input is given to the encoder in English language and is transliterated to Hindi\n",
    "by the decoder'''\n",
    "path_train=\"hin_train.csv\"\n",
    "language_names = ['English','transliteration_in_hindi']\n",
    "df_train=load_data(path_train,language_names)\n",
    "print(df_train.shape)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0295381c-c8ef-44dd-a889-50227c3fa9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data: (4096, 2)\n",
      "Test data: (4096, 2)\n"
     ]
    }
   ],
   "source": [
    "path_test=\"hin_test.csv\"\n",
    "path_validation=\"hin_valid.csv\"\n",
    "df_validation=load_data(path_validation,language_names)\n",
    "print('Validation data:',df_validation.shape)\n",
    "df_test=load_data(path_test,language_names)\n",
    "print('Test data:', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a300425-3ef3-4143-8431-fdba708fa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for acquiring all the characters of the given data'''\n",
    "def split_words(x):\n",
    "    x=np.array(x)\n",
    "    alpha=['_','\\t','\\n',' '] #pad token, start of word, end of word and unknown tokens respectively\n",
    "    b=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        a=list(x[i])\n",
    "        for j in range(len(a)):\n",
    "            if a[j] not in b:\n",
    "                b.append(a[j])\n",
    "    b=sorted(b)\n",
    "    alpha=alpha+b\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd8106a-23da-46d3-a671-a0f6bcc76452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 30\n",
      "Hindi vocabulary size: 68\n",
      "['_', '\\t', '\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['_', '\\t', '\\n', ' ', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n"
     ]
    }
   ],
   "source": [
    "'''All the english characters are stored into the list english_vocab and all the hindi characters are\n",
    "stored into the list hindi_vocab'''\n",
    "english_vocab=split_words(df_train['English'])\n",
    "hindi_vocab=split_words(df_train['transliteration_in_hindi'])\n",
    "print('English vocabulary size:', len(english_vocab))\n",
    "print('Hindi vocabulary size:', len(hindi_vocab))\n",
    "print(english_vocab)\n",
    "print(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e39689b-9116-4002-b77a-63d3d3ca81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions to create the vocabulary dictionaries with their corresponding indices'''\n",
    "def int_to_char(vocab):\n",
    "    int2char={} #padding token, start of word, end of word token and unknown token\n",
    "    for i in range(len(vocab)):\n",
    "        int2char[i]=vocab[i]\n",
    "    return int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d068ba44-5050-4672-adb9-f8c557e77e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    }
   ],
   "source": [
    "int2char_eng=int_to_char(english_vocab)\n",
    "print(int2char_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af101473-30b0-43bc-936b-807aa42b036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_int(int2char):\n",
    "    char2int={ch:ii for ii,ch in int2char.items()}\n",
    "    return char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7c311b-1e25-43b9-9f8b-8c0261ec8e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "char2int_eng=char_to_int(int2char_eng)\n",
    "print(char2int_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda25faf-47bb-41b8-a0e9-3a7ac8516085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "int2char_hin=int_to_char(hindi_vocab)\n",
    "print(int2char_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc02904-626f-448d-8904-6110bd906aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'अ': 7, 'आ': 8, 'इ': 9, 'ई': 10, 'उ': 11, 'ऊ': 12, 'ऋ': 13, 'ए': 14, 'ऐ': 15, 'ऑ': 16, 'ओ': 17, 'औ': 18, 'क': 19, 'ख': 20, 'ग': 21, 'घ': 22, 'ङ': 23, 'च': 24, 'छ': 25, 'ज': 26, 'झ': 27, 'ञ': 28, 'ट': 29, 'ठ': 30, 'ड': 31, 'ढ': 32, 'ण': 33, 'त': 34, 'थ': 35, 'द': 36, 'ध': 37, 'न': 38, 'प': 39, 'फ': 40, 'ब': 41, 'भ': 42, 'म': 43, 'य': 44, 'र': 45, 'ल': 46, 'ळ': 47, 'व': 48, 'श': 49, 'ष': 50, 'स': 51, 'ह': 52, '़': 53, 'ऽ': 54, 'ा': 55, 'ि': 56, 'ी': 57, 'ु': 58, 'ू': 59, 'ृ': 60, 'ॅ': 61, 'े': 62, 'ै': 63, 'ॉ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n"
     ]
    }
   ],
   "source": [
    "char2int_hin=char_to_int(int2char_hin)\n",
    "print(char2int_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ea6931-8919-4cb1-8dfa-e2f110e8a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finding the maximum sequence length'''\n",
    "length_eng=[len(i) for i in df_train['English']]\n",
    "length_hin=[len(i) for i in df_train['transliteration_in_hindi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8154e97-4505-4a54-ac9b-256652574cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sequence length of English words is 26\n",
      "The maximum sequence length of transliterated words is 22\n"
     ]
    }
   ],
   "source": [
    "length_eng_max=max(length_eng)+2 #we have to account for the start and end token\n",
    "print(f'The maximum sequence length of English words is {length_eng_max}')\n",
    "length_hin_max=max(length_hin)+2\n",
    "print(f'The maximum sequence length of transliterated words is {length_hin_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e01597ef-66bc-4acf-8162-eecc99d44da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df['English'] = df['English'].str.lower()\n",
    "    df['transliteration_in_hindi'] = df['transliteration_in_hindi'].str.lower()\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    \n",
    "    '''Adding start and end of word tokens'''\n",
    "    y_og = df['transliteration_in_hindi'].values #The data type of y_og will be numpy array\n",
    "    x_og = df['English'].values\n",
    "    x = '\\t'+x_og+'\\n'\n",
    "    y = '\\t'+y_og+'\\n'\n",
    "    y_do=y_og+'\\n' #This is for the decoder output\n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    \n",
    "    enc_input_data=torch.zeros(len(x),length_eng_max)\n",
    "    dec_input_data=torch.zeros(len(y),length_hin_max)\n",
    "    dec_output_data=torch.zeros(len(y),length_hin_max)\n",
    "    for i, (xx,yy) in enumerate(zip(x,y)):\n",
    "        for j,char in enumerate(xx):\n",
    "            enc_input_data[i,j]=char2int_eng[char]\n",
    "            \n",
    "        #pad character is zero so no need of assigning it again\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_input_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char] #There are chances that unknown char would come in the test data\n",
    "    \n",
    "    for i, (xx,yy) in enumerate(zip(x,y_do)):\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_output_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char]\n",
    "                \n",
    "    return enc_input_data,dec_input_data,dec_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b47e667-daf1-4d6a-9619-6d93e0220654",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data,dec_input_data,dec_output_data=process_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f84c38-e7c6-4642-8c26-e1aa1a068b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26])\n",
      "torch.Size([51200, 22])\n",
      "torch.Size([51200, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data.shape)\n",
    "print(dec_input_data.shape)\n",
    "print(dec_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5b84d5-fd05-485e-899e-510f71b917da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9c85674-87f1-4db1-a615-5468f8b3a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    '''Adding start and end of word tokens'''\n",
    "    y = df['transliteration_in_hindi'].values\n",
    "    x= df['English'].values\n",
    "    x = '\\t'+x+'\\n'\n",
    "    y = '\\t'+y+'\\n'\n",
    "    \n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    num_english_tokens = len(english_vocab)\n",
    "    num_hindi_tokens = len(hindi_vocab)\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(df['English']), length_eng_max, num_english_tokens), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "    decoder_output_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "   \n",
    "    for i , (input_text,target_text) in enumerate(zip(x,y)):\n",
    "        for t,char in enumerate(input_text):\n",
    "            encoder_input_data[i,t,char2int_eng[char]]=1\n",
    "        encoder_input_data[i,t+1:,char2int_eng[pad_char]]=1\n",
    "    \n",
    "        for t,char in enumerate(target_text):\n",
    "            if char in hindi_vocab:\n",
    "                decoder_input_data[i,t,char2int_hin[char]]=1\n",
    "            else:\n",
    "                decoder_input_data[i,t,char2int_hin[unknown_char]]=1\n",
    "        decoder_input_data[i,t+1:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "        '''decoder target data is one step ahead of decoder input data by one timestep\n",
    "        and doesnot includes start token'''\n",
    "        for t,char in enumerate(target_text):\n",
    "            if t>0:\n",
    "                if char in hindi_vocab:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[char]]=1\n",
    "                else:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[unknown_char]]=1\n",
    "                \n",
    "        decoder_output_data[i,t:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "    return torch.tensor(encoder_input_data),torch.tensor(decoder_input_data),torch.tensor(decoder_output_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff395a6e-559d-4174-ad48-fae21f5d8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data,decoder_input_data,decoder_output_data=one_hot_encoding(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d094fd8-7114-4c87-8e22-683af1761148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26, 30])\n",
      "torch.Size([51200, 22, 68])\n",
      "torch.Size([51200, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "727a0901-3c28-4786-a5ef-2095d1267f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data_test,dec_input_data_test,dec_output_data_test=process_data(df_test)\n",
    "enc_input_data_val,dec_input_data_val,dec_output_data_val=process_data(df_validation)\n",
    "encoder_input_data_test,decoder_input_data_test,decoder_output_data_test=one_hot_encoding(df_test)\n",
    "encoder_input_data_val,decoder_input_data_val,decoder_output_data_val=one_hot_encoding(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74d097ee-cdbc-412e-9e2d-7e3b38e686b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 26, 30])\n",
      "torch.Size([4096, 22, 68])\n",
      "torch.Size([4096, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)\n",
    "print(decoder_output_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d367cb8c-69d8-41e5-a8ae-10fc3b113d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 49, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 41, 56,  ...,  0,  0,  0],\n",
      "        [ 1, 19, 56,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  7, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 51, 58,  ...,  0,  0,  0],\n",
      "        [ 1,  7,  5,  ...,  0,  0,  0]])\n",
      "tensor([[ 1., 49., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 41., 56.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 19., 56.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 1.,  7., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 51., 58.,  ...,  0.,  0.,  0.],\n",
      "        [ 1.,  7.,  5.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(decoder_input_data,dim=-1))\n",
    "print(dec_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84e4b3f5-6b52-4b40-ba66-cb9e61419751",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data=enc_input_data.long()\n",
    "dec_input_data=dec_input_data.long()\n",
    "enc_input_data_test=enc_input_data_test.long()\n",
    "dec_input_data_test=dec_input_data_test.long()\n",
    "enc_input_data_val=enc_input_data_val.long()\n",
    "dec_input_data_val=dec_input_data_val.long()\n",
    "encoder_input_data=encoder_input_data.long()\n",
    "decoder_input_data=decoder_input_data.long()\n",
    "decoder_output_data=decoder_output_data.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d80a749-e651-4fe4-9ffa-0cd4cd57c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(x,y,z,batch_size,device=device):\n",
    "    \n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    z=z.to(device)\n",
    "    combined=TensorDataset(x,y,z)\n",
    "    loader=DataLoader(combined,batch_size=batch_size,shuffle=False,drop_last=True)#required in test data\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93141f2-822c-4295-a033-45753c8ab51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere, the implementation is based on the paper: Attention is all you need\\nThe original base attention transformer has the following structure:\\n\\nMain dimension of model-embeddings (d_model): 512\\nNumber of attention heads: 8\\nNumber of encoder layers: 6\\nNumber of decoder layers: 6\\nHidden dimension of feed-forward layers: 2048\\nDropout probability: 0.1\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here, the implementation is based on the paper: Attention is all you need\n",
    "The original base attention transformer has the following structure:\n",
    "\n",
    "Main dimension of model-embeddings (d_model): 512\n",
    "Number of attention heads: 8\n",
    "Number of encoder layers: 6\n",
    "Number of decoder layers: 6\n",
    "Hidden dimension of feed-forward layers: 2048\n",
    "Dropout probability: 0.1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "858539cc-9d23-4360-b187-ad99980dfe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_generator(x, heads, seq_len_dec = None, type = 'encoder_selfattention'):\n",
    "\n",
    "    '''\n",
    "    Here, the output will be of the format (bs, heads, seq_len, seq_len), which can be used for masking in the multihead attention block\n",
    "    before applying softmax function\n",
    "    types : Encoder self attention(bs, seq_len, enc_seqlen, enc_seqlen)\n",
    "            Decoder self attention(bs, seq_len, dec_seqlen, dec_seqlen)\n",
    "            Decoder cross attention(bs, seq_len, dec_seqlen, enc_seqlen)\n",
    "    '''\n",
    "    \n",
    "    if type == 'encoder_selfattention':\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        pad_idx = 0\n",
    "        mask = (x == pad_idx)\n",
    "        '''\n",
    "        Expand the mask for attention (batch_size, num_heads, seq_len, seq_len); after doing the operation q.kT the shape will be this\n",
    "        '''\n",
    "        mask = mask.unsqueeze(1).unsqueeze(2).expand(batch_size, heads, seq_len, seq_len).detach().to(device)\n",
    "        \n",
    "    elif type == 'decoder_selfattention':\n",
    "        '''Here, this masking is used in decoder to avoid the present tokens seeing the future ones'''\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        mask = torch.triu(torch.ones(seq_len,seq_len)*float('-inf'), diagonal = 1).bool().expand(batch_size, heads, seq_len, seq_len).detach().to(device)\n",
    "\n",
    "    elif type  == 'decoder_crossattention':\n",
    "        '''Here, we use the padding_mask of encoder and the sequence length should be that of encoder\n",
    "        output : (batch size, heads, decoder sequence length, encoder sequence langth'''\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len_enc = x.shape[1]\n",
    "        pad_idx = 0\n",
    "        mask = (x == pad_idx)\n",
    "        mask = mask.unsqueeze(1).unsqueeze(2).expand(batch_size, heads, seq_len_dec, seq_len_enc).detach().to(device)\n",
    "        \n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f7b4ddd-cffc-4efe-b464-21e85ddbf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_embedding(batch_size, seq_length, d_model, device):\n",
    "    '''\n",
    "    x : (batch_size, seq_length)\n",
    "    embed : (batch_size, seq_length, d_model)\n",
    "    Gradient won't flow through positional embedding\n",
    "    '''\n",
    "    embed = torch.zeros((batch_size, seq_length, d_model), device=device, requires_grad=False)\n",
    "    \n",
    "    pos = torch.arange(seq_length, dtype=torch.float, device=device).unsqueeze(1)\n",
    "    div = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float, device=device) * (-math.log(10000.0) / d_model))\n",
    "    \n",
    "    embed[:, :, 0::2] = torch.sin(pos * div)\n",
    "    embed[:, :, 1::2] = torch.cos(pos * div)\n",
    "\n",
    "    return embed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f452d5a-dd76-4547-9a0e-96d515135c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiheadattention(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model, h, dropout):\n",
    "        \n",
    "        super(multiheadattention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = h\n",
    "        self.d_k = d_model//h\n",
    "        self.q = nn.Linear(d_model,d_model, bias = False)\n",
    "        self.k = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.v = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.outputprojectionlayer = nn.Linear(d_model,d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self,w, mask):\n",
    "        '''x: Input data after performing positional and word embeddings and adding both\n",
    "           att_scores : output of same shape\n",
    "           d_model shpuld be divisible by number of heads\n",
    "        '''\n",
    "        q = self.q(w[0])\n",
    "        k = self.k(w[1])\n",
    "        v = self.v(w[2])\n",
    "\n",
    "        bs = q.shape[0]\n",
    "        seq_len1 = w[0].shape[1]\n",
    "        seq_len2 = w[1].shape[1]\n",
    "        q = q.view(bs, seq_len1, self.heads, self.d_k).transpose(1, 2)\n",
    "        k = k.view(bs, seq_len2, self.heads, self.d_k).transpose(1, 2)\n",
    "        v = v.view(bs, seq_len2, self.heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        att_scores = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            att_scores = att_scores.masked_fill(mask,float('-inf'))\n",
    "            \n",
    "        att_scores = F.softmax(att_scores, dim = -1)\n",
    "        #att_scores = self.dropout(att_scores)\n",
    "        att = torch.matmul(att_scores, v)\n",
    "        \n",
    "        #Concatenating the heads to form the shape of (bs, seq_len, d_model)\n",
    "        att = att.transpose(1, 2).contiguous().view(bs, seq_len1, self.d_model)\n",
    "        \n",
    "        output = self.outputprojectionlayer(att)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb122e3e-8967-424f-a337-1c1561e7b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pointwiseffnn(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_hidden):\n",
    "        super(pointwiseffnn, self).__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.d_model = d_model\n",
    "        self.linearlayer1 = nn.Linear(d_model, d_hidden)\n",
    "        self.linearlayer2 = nn.Linear(d_hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        This is the pointwise feedforward layer after attention block, which consists of 2 linear layers, a relu\n",
    "        '''\n",
    "        x = self.linearlayer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linearlayer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18a57b7e-b199-4b7e-813c-26114493c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoderlayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, h, d_hidden, dropout):\n",
    "        '''\n",
    "        d_model : Embedding dimension(512)\n",
    "        h : Number of heads(8)\n",
    "        N : number of attention layers(6)\n",
    "        d_k : d_model/h\n",
    "        seq : Maximum sequence length of English(26)\n",
    "        vocab_size : Number of English characters in the corpus(30)\n",
    "        epsilon : used for layer normalization (10e-5)\n",
    "        '''\n",
    "        super(Encoderlayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = h\n",
    "        self.d_k = d_model//h\n",
    "        self.d_hidden = d_hidden\n",
    "        self.mha = multiheadattention(d_model, h, dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(self.d_model)\n",
    "        self.pffnn = pointwiseffnn(d_model, d_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layernorm2 = nn.LayerNorm(self.d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x, sam):\n",
    "            \n",
    "        x_mha = self.mha([x, x, x], sam)\n",
    "        x_mha = self.dropout1(x_mha)\n",
    "        x_out1 = self.layernorm1(x + x_mha)\n",
    "        \n",
    "        x_pffnn = self.pffnn(x_out1)\n",
    "        x_pffnn = self.dropout2(x_pffnn)\n",
    "        x_out2 = self.layernorm2(x_out1 + x_pffnn)\n",
    "\n",
    "        return x_out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03eb9903-0100-474a-8163-126cc0d11a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function can be used to create multiple encoder blocks with different weights, here we need 6 encoder blocks'''\n",
    "def multipleblocks(block, N):\n",
    "    \n",
    "    return nn.ModuleList([copy.deepcopy(block) for i in range(N)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c879467b-34d2-48e0-81a5-776b4f566dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, h, vocab_size_encoder, N, d_hidden, dropout):\n",
    "        '''\n",
    "        d_model : Embedding dimension(512)\n",
    "        h : Number of heads(8)\n",
    "        N : number of attention layers(6)\n",
    "        d_k : d_model/h\n",
    "        seq : Maximum sequence length of English(26)\n",
    "        vocab_size : Number of English characters in the corpus(30)\n",
    "        epsilon : used for layer normalization (10e-5)\n",
    "        pe_encoder : Positional embedding of Encoder input\n",
    "        \n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = h\n",
    "        self.d_k = d_model//h\n",
    "        self.vocab_size_encoder = vocab_size_encoder\n",
    "        self.N = N\n",
    "        self.d_hidden = d_hidden\n",
    "        self.embedding = nn.Embedding(vocab_size_encoder, d_model, padding_idx = 0)\n",
    "        self.layers = multipleblocks(Encoderlayer(d_model, h, d_hidden, dropout), N)\n",
    "        \n",
    "        assert self.d_model % self.heads == 0\n",
    "\n",
    "\n",
    "    def forward(self, x, sam, pe):\n",
    "        '''\n",
    "        x : Encoder input embedded\n",
    "        sam : self attention padding mask\n",
    "        '''\n",
    "\n",
    "        x_wv = self.embedding(x)\n",
    "        x = x_wv + pe\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, sam)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02cf5c1a-92d4-47d4-8353-fea236de6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoderlayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, h, d_hidden, dropout):\n",
    "       \n",
    "        '''\n",
    "        d_model : Embedding dimension(512)\n",
    "        h : Number of heads(8)\n",
    "        N : number of attention layers(6)\n",
    "        d_k : d_model/h\n",
    "        seq : Maximum sequence length of English(26)\n",
    "        vocab_size : Number of English characters in the corpus(30)\n",
    "        epsilon : used for layer normalization (10e-5)\n",
    "        '''\n",
    "        super(Decoderlayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = h\n",
    "        self.d_hidden = d_hidden\n",
    "        self.mha_self = multiheadattention(d_model, h, dropout)\n",
    "        self.mha_cross = multiheadattention(d_model, h, dropout)\n",
    "        self.layernorm1 = nn.LayerNorm(self.d_model)\n",
    "        self.pffnn = pointwiseffnn(d_model, d_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.layernorm2 = nn.LayerNorm(self.d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(self.d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, sam, cam):\n",
    "        '''\n",
    "        x : embedded decoder input\n",
    "        y : encoder output\n",
    "        sam : Self Attention mask\n",
    "        cam : cross attention mask\n",
    "        \n",
    "        '''\n",
    "            \n",
    "        x_mha_self = self.mha_self([x, x, x], sam)\n",
    "        x_mha_self = self.dropout1(x_mha_self)\n",
    "        x_out1 = self.layernorm1(x + x_mha_self)\n",
    "        \n",
    "        x_mha_cross = self.mha_cross([x, y, y], cam)\n",
    "        x_mha_cross = self.dropout2(x_mha_self)\n",
    "        x_out2 = self.layernorm2(x_out1 + x_mha_cross)\n",
    "        \n",
    "        x_pffnn = self.pffnn(x_out2)\n",
    "        x_pffnn = self.dropout2(x_pffnn)\n",
    "        x_out3 = self.layernorm3(x_out2 + x_pffnn)\n",
    "\n",
    "        return x_out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5940497-92ca-462d-a052-b5b2dc14471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, h, vocab_size_decoder, N, d_hidden, dropout):\n",
    "        '''\n",
    "        d_model : Embedding dimension(512)\n",
    "        h : Number of heads(8)\n",
    "        N : number of attention layers(6)\n",
    "        d_k : d_model/h\n",
    "        seq : Maximum sequence length of English(26)\n",
    "        vocab_size : Number of English characters in the corpus(30)\n",
    "        epsilon : used for layer normalization (10e-5)\n",
    "        pe_decoder : Positional embedding of Decoder input\n",
    "        '''\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = h\n",
    "        self.d_k = d_model//h\n",
    "        self.vocab_size_decoder = vocab_size_decoder\n",
    "        self.N = N\n",
    "        self.d_hidden = d_hidden\n",
    "        self.embedding = nn.Embedding(vocab_size_decoder, d_model, padding_idx = 0)\n",
    "        self.layers = multipleblocks(Decoderlayer(d_model, h, d_hidden, dropout), N)\n",
    "        \n",
    "        assert self.d_model % self.heads == 0\n",
    "\n",
    "\n",
    "    def forward(self, x, y, sam, cam, pe):\n",
    "        '''\n",
    "        x : decoder input\n",
    "        y : encoder output\n",
    "        sam : Self Attention Mask\n",
    "        cam : Cross Attention Mask\n",
    "        pe : positional embedding of decoder tokens\n",
    "        \n",
    "        '''\n",
    "\n",
    "        x_wv = self.embedding(x)\n",
    "        x = x_wv + pe\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, y, sam, cam)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b38476b8-8aac-40b1-b9dd-effffdbae983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, heads, vocab_size_encoder, vocab_size_decoder, N, d_hidden, dropout):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_k = d_model//heads\n",
    "        self.N = N\n",
    "        self.d_hidden = d_hidden\n",
    "        self.dropout = dropout\n",
    "        self.vocab_size_encoder = vocab_size_encoder\n",
    "        self.vocab_size_decoder = vocab_size_decoder\n",
    "        self.encoder = Encoder(d_model, heads, vocab_size_encoder, N, d_hidden, dropout)\n",
    "        self.decoder = Decoder(d_model, heads, vocab_size_decoder, N, d_hidden, dropout)\n",
    "\n",
    "        self.linear = nn.Linear(d_model, vocab_size_decoder)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, encoder_sam, decoder_sam, decoder_cam, enc_pe, dec_pe):\n",
    "        '''\n",
    "        x : encoder input data\n",
    "        y : decoder input data\n",
    "        encoding : encoder output data\n",
    "        decoding : decoder output data\n",
    "        No need to find the softmax/probability values as it will be already taken care by Cross Entropy loss function.\n",
    "        '''\n",
    "\n",
    "        encoding = self.encoder(x, encoder_sam, enc_pe)\n",
    "        decoding = self.decoder(y, encoding, decoder_sam, decoder_cam, dec_pe)\n",
    "\n",
    "        logits = self.linear(decoding)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3c40932-985b-4adc-8c84-690eae793565",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set the value of hyper parameters before training\n",
    "'''\n",
    "d_model = 512\n",
    "d_hidden = 2048\n",
    "vocab_size_encoder = 30\n",
    "vocab_size_decoder = 68\n",
    "N = 6\n",
    "heads = 8\n",
    "dropout = 0.1\n",
    "seq_len_encoder = 26\n",
    "seq_len_decoder = 22\n",
    "learning_rate = 0.0001\n",
    "epsilon = 1e-9\n",
    "betas = (0.9, 0.98)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33561f1e-6e6d-4bf5-ab97-4558108ff5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating an instance of transformer, optimizer, loss function\n",
    "'''\n",
    "model = Transformer(d_model, heads, vocab_size_encoder, vocab_size_decoder, N, d_hidden, dropout)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas = betas, eps = epsilon)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12a641dc-bb87-41df-b698-e8883a90e4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Transformer(\n",
      "    (encoder): Encoder(\n",
      "      (embedding): Embedding(30, 512, padding_idx=0)\n",
      "      (layers): ModuleList(\n",
      "        (0): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): Encoderlayer(\n",
      "          (mha): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (embedding): Embedding(68, 512, padding_idx=0)\n",
      "      (layers): ModuleList(\n",
      "        (0): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): Decoderlayer(\n",
      "          (mha_self): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (mha_cross): multiheadattention(\n",
      "            (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (outputprojectionlayer): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layernorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (pffnn): pointwiseffnn(\n",
      "            (linearlayer1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (linearlayer2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "          (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (layernorm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=512, out_features=68, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Assigning the transformer object into multiple GPUs\n",
    "'''\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "add5d14a-dc8e-48c5-ad78-62462235f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 26])\n",
      "torch.Size([8, 22])\n",
      "torch.Size([8, 22])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creating data loader\n",
    "'''\n",
    "batch_size = 8\n",
    "train_loader = data_loader(enc_input_data, dec_input_data, dec_output_data, batch_size)\n",
    "for i, (x, y, z) in enumerate(train_loader):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(z.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56df171d-319a-4109-ab6d-3dcddec655e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_accuracy(dec_predicted_data, dec_output_data):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        match = (dec_predicted_data == dec_output_data).all(dim=1)\n",
    "        true_words = match.sum().item()\n",
    "        batch_size = dec_predicted_data.shape[0]\n",
    "    \n",
    "    accuracy = (true_words / batch_size) * 100 #Averaged over batch\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e4b0796-7536-46c1-a789-6b8caf1dc3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_char_accuracy(decoder_predicted_data, decoder_output_data):\n",
    "   \n",
    "    batch_size, seq_length = decoder_predicted_data.shape\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_count = (decoder_predicted_data == decoder_output_data).sum().item() #Averaged over batch\n",
    "        return (correct_count / (seq_length * batch_size))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71675722-6693-4550-ad61-2673f677b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 26, 512])\n",
      "torch.Size([8, 22, 512])\n"
     ]
    }
   ],
   "source": [
    "enc_pe = positional_embedding(batch_size, seq_len_encoder, d_model, x.device)\n",
    "dec_pe = positional_embedding(batch_size, seq_len_decoder, d_model, y.device)\n",
    "print(enc_pe.shape)\n",
    "print(dec_pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "943bbc16-980f-4163-ab47-5a118b7bd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, epochs, heads, batch_size, d_model, \n",
    "                                                                     enc_pe, dec_pe, device = device):\n",
    "\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    char_history = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        epoch_char_acc = 0.0\n",
    "        for i, (x, y, z) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "            '''\n",
    "            enc_pe : Positional embedding of encoder input(no grad flow)\n",
    "            dec_pe : Positional embedding of decoder input(no grad flow)\n",
    "            esm : Encoder self attention mask\n",
    "            dsm : Decoder self attention mask\n",
    "            dcm : Decoder cross attention mask\n",
    "            '''\n",
    "            esm = mask_generator(x, heads, type = 'encoder_selfattention').to(device)\n",
    "            dsm = mask_generator(y, heads, type = 'decoder_selfattention').to(device)\n",
    "            dcm = mask_generator(x, heads, y.shape[1], type = 'decoder_crossattention').to(device)\n",
    "            \n",
    "            preds = model(x, y, esm, dsm, dcm, enc_pe, dec_pe)\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(preds.contiguous().view(-1, preds.shape[-1]), z.contiguous().view(-1).long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            word_acc = calculate_word_accuracy(torch.argmax(preds, dim = -1), z)\n",
    "            char_acc = calculate_char_accuracy(torch.argmax(preds, dim = -1), z)\n",
    "            epoch_acc += word_acc\n",
    "            epoch_char_acc += char_acc\n",
    "\n",
    "        loss_history.append(epoch_loss)\n",
    "        accuracy_history.append(epoch_acc / (i + 1))\n",
    "        char_history.append(epoch_char_acc / (i + 1))\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc / (i + 1):.4f}, Char Accuracy: {epoch_char_acc / (i + 1):.4f}\")\n",
    "\n",
    "    return loss_history, accuracy_history, char_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96ace2e6-c345-412e-8724-68008d0ac5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:53<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 6949.8813, Accuracy: 0.0000, Char Accuracy: 69.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 6472.0356, Accuracy: 0.0000, Char Accuracy: 71.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 6280.2604, Accuracy: 0.0000, Char Accuracy: 72.2752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 6135.7575, Accuracy: 0.0000, Char Accuracy: 72.8248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 6013.5035, Accuracy: 0.0000, Char Accuracy: 73.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 5906.7635, Accuracy: 0.0000, Char Accuracy: 73.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 5809.7378, Accuracy: 0.0000, Char Accuracy: 74.0323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:52<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 5710.7725, Accuracy: 0.0000, Char Accuracy: 74.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 5622.5738, Accuracy: 0.0000, Char Accuracy: 74.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 5535.1205, Accuracy: 0.0000, Char Accuracy: 75.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 5450.0069, Accuracy: 0.0000, Char Accuracy: 75.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 5366.2394, Accuracy: 0.0000, Char Accuracy: 75.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 5284.1572, Accuracy: 0.0020, Char Accuracy: 75.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 5207.0513, Accuracy: 0.0000, Char Accuracy: 76.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 5132.7220, Accuracy: 0.0000, Char Accuracy: 76.5768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 5062.5210, Accuracy: 0.0000, Char Accuracy: 76.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 4991.9237, Accuracy: 0.0000, Char Accuracy: 77.1204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 4919.9772, Accuracy: 0.0000, Char Accuracy: 77.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 4858.4123, Accuracy: 0.0000, Char Accuracy: 77.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 4792.7070, Accuracy: 0.0000, Char Accuracy: 77.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 4737.2415, Accuracy: 0.0000, Char Accuracy: 78.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:52<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 4678.4045, Accuracy: 0.0000, Char Accuracy: 78.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 4624.5405, Accuracy: 0.0020, Char Accuracy: 78.5968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 4576.1431, Accuracy: 0.0020, Char Accuracy: 78.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 4526.6017, Accuracy: 0.0000, Char Accuracy: 78.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 4479.4443, Accuracy: 0.0000, Char Accuracy: 79.1709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 4434.8785, Accuracy: 0.0000, Char Accuracy: 79.3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 4399.7177, Accuracy: 0.0000, Char Accuracy: 79.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 4362.7630, Accuracy: 0.0039, Char Accuracy: 79.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 4322.9040, Accuracy: 0.0020, Char Accuracy: 79.8509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 4291.1073, Accuracy: 0.0020, Char Accuracy: 79.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 4258.3948, Accuracy: 0.0000, Char Accuracy: 80.1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 4222.8467, Accuracy: 0.0020, Char Accuracy: 80.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 4195.3809, Accuracy: 0.0020, Char Accuracy: 80.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 4166.6188, Accuracy: 0.0039, Char Accuracy: 80.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:50<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 4139.2062, Accuracy: 0.0000, Char Accuracy: 80.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:49<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 4112.8675, Accuracy: 0.0020, Char Accuracy: 80.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:51<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 4090.1601, Accuracy: 0.0020, Char Accuracy: 80.9039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:54<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 4066.2669, Accuracy: 0.0020, Char Accuracy: 80.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:53<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 4048.4396, Accuracy: 0.0020, Char Accuracy: 81.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|█████████████████████████████████████████████████████████████████| 6400/6400 [15:54<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 4021.8795, Accuracy: 0.0020, Char Accuracy: 81.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100:   5%|███▏                                                              | 308/6400 [00:46<15:14,  6.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31581/2225051192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m loss_history, accuracy_history, char_history = train(model, optimizer, loss, train_loader, epochs, heads, batch_size, d_model, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                                      enc_pe, dec_pe, device = device)\n",
      "\u001b[0;32m/tmp/ipykernel_31581/2889261139.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, epochs, heads, batch_size, d_model, enc_pe, dec_pe, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history, accuracy_history, char_history = train(model, optimizer, loss, train_loader, epochs, heads, batch_size, d_model, \n",
    "                                                                     enc_pe, dec_pe, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb13915b-c0bd-48d5-af66-6482141f43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, epoch, loss_history, accuracy_history, char_history, filepath):\n",
    "    \"\"\"\n",
    "    Save the model state, optimizer state, epoch, and training history to a file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to be saved.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used in training.\n",
    "        epoch (int): The current epoch number.\n",
    "        loss_history (list): List of loss values per epoch.\n",
    "        accuracy_history (list): List of accuracy values per epoch.\n",
    "        char_history (list): List of character accuracy values per epoch.\n",
    "        filepath (str): The path to the file where the state will be saved.\n",
    "    \"\"\"\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss_history': loss_history,\n",
    "        'accuracy_history': accuracy_history,\n",
    "        'char_history': char_history\n",
    "    }\n",
    "    torch.save(state, filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bee881c-dd2d-4506-95a1-8d71c16c39f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31581/848453848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_checkpoint.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_history' is not defined"
     ]
    }
   ],
   "source": [
    "#save_model(model, optimizer, 41, loss_history, accuracy_history, char_history, 'model_checkpoint.pth')\n",
    "save_model(model, optimizer, 41, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2915e3-9f41-4f4a-aabc-e767d070cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, optimizer, filepath):\n",
    "    \"\"\"\n",
    "    Load the model state, optimizer state, epoch, and training history from a file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to be loaded.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used in training.\n",
    "        filepath (str): The path to the file from where the state will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        int: The epoch number from which to resume training.\n",
    "        list: List of loss values per epoch.\n",
    "        list: List of accuracy values per epoch.\n",
    "        list: List of character accuracy values per epoch.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss_history = checkpoint['loss_history']\n",
    "    accuracy_history = checkpoint['accuracy_history']\n",
    "    char_history = checkpoint['char_history']\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return epoch, loss_history, accuracy_history, char_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef148c-065e-4289-ad98-2fa29bbf9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, loss_history, accuracy_history, char_history = load_model(model, optimizer, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dddf46-0634-4cd4-b177-41bf2ce88772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
