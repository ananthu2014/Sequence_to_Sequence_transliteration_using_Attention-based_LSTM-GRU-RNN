{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabfad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import random\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3654d4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0aa7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = '/home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c662162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mananthu2014\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0da7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function to load the data'''\n",
    "def load_data(path,language_names):\n",
    "    df=pd.read_csv(path,header=None)\n",
    "    df.columns=language_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75791f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shastragaar</td>\n",
       "      <td>शस्त्रागार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>toned</td>\n",
       "      <td>टोंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>mutanaazaa</td>\n",
       "      <td>मुतनाज़ा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>asahmaton</td>\n",
       "      <td>असहमतों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>sulgaayin</td>\n",
       "      <td>सुलगायीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>anchuthengu</td>\n",
       "      <td>अंचुतेंगु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           English transliteration_in_hindi\n",
       "0      shastragaar               शस्त्रागार\n",
       "1          bindhya                 बिन्द्या\n",
       "2        kirankant                 किरणकांत\n",
       "3      yagyopaveet                यज्ञोपवीत\n",
       "4          ratania                  रटानिया\n",
       "...            ...                      ...\n",
       "51195        toned                     टोंड\n",
       "51196   mutanaazaa                 मुतनाज़ा\n",
       "51197    asahmaton                  असहमतों\n",
       "51198    sulgaayin                 सुलगायीं\n",
       "51199  anchuthengu                अंचुतेंगु\n",
       "\n",
       "[51200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Here,basically,the input is given to the encoder in English language and is transliterated to Hindi\n",
    "by the decoder'''\n",
    "path_train=\"/home/agcl/Downloads/hin_train.csv\"\n",
    "language_names = ['English','transliteration_in_hindi']\n",
    "df_train=load_data(path_train,language_names)\n",
    "print(df_train.shape)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b822674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 2)\n",
      "(4096, 2)\n"
     ]
    }
   ],
   "source": [
    "#path_test=\"C:/Users/anant/Downloads/hin_test.csv\"\n",
    "path_test=\"/home/agcl/Downloads/hin_test.csv\"\n",
    "#path_validation=\"C:/Users/anant/Downloads/hin_valid.csv\"\n",
    "path_validation=\"/home/agcl/Downloads/hin_valid.csv\"\n",
    "df_validation=load_data(path_validation,language_names)\n",
    "print(df_validation.shape)\n",
    "df_test=load_data(path_test,language_names)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f13c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for acquiring all the characters of the given data'''\n",
    "def split_words(x):\n",
    "    x=np.array(x)\n",
    "    alpha=['_','\\t','\\n',' '] #pad token, start of word, end of word and unknown tokens\n",
    "    b=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        a=list(x[i])\n",
    "        for j in range(len(a)):\n",
    "            if a[j] not in b:\n",
    "                b.append(a[j])\n",
    "    b=sorted(b)\n",
    "    alpha=alpha+b\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d5c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''All the english characters are stored into the list english_vocab and all the hindi characters are\n",
    "stored into the list hindi_vocab'''\n",
    "english_vocab=split_words(df_train['English'])\n",
    "hindi_vocab=split_words(df_train['transliteration_in_hindi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766389b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "68\n",
      "['_', '\\t', '\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['_', '\\t', '\\n', ' ', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n"
     ]
    }
   ],
   "source": [
    "print(len(english_vocab))\n",
    "print(len(hindi_vocab))\n",
    "print(english_vocab)\n",
    "print(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209154f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions to create the vocabulary dictionaries with their indices'''\n",
    "def int_to_char(vocab):\n",
    "    int2char={} #padding token, start of word, end of word token and unknown token\n",
    "    for i in range(len(vocab)):\n",
    "        int2char[i]=vocab[i][0]\n",
    "    return int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49dc0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    }
   ],
   "source": [
    "int2char_eng=int_to_char(english_vocab)\n",
    "print(int2char_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a0b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_int(int2char):\n",
    "    char2int={ch:ii for ii,ch in int2char.items()}\n",
    "    return char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6336f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "char2int_eng=char_to_int(int2char_eng)\n",
    "print(char2int_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5edad018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "int2char_hin=int_to_char(hindi_vocab)\n",
    "print(int2char_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c7a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'अ': 7, 'आ': 8, 'इ': 9, 'ई': 10, 'उ': 11, 'ऊ': 12, 'ऋ': 13, 'ए': 14, 'ऐ': 15, 'ऑ': 16, 'ओ': 17, 'औ': 18, 'क': 19, 'ख': 20, 'ग': 21, 'घ': 22, 'ङ': 23, 'च': 24, 'छ': 25, 'ज': 26, 'झ': 27, 'ञ': 28, 'ट': 29, 'ठ': 30, 'ड': 31, 'ढ': 32, 'ण': 33, 'त': 34, 'थ': 35, 'द': 36, 'ध': 37, 'न': 38, 'प': 39, 'फ': 40, 'ब': 41, 'भ': 42, 'म': 43, 'य': 44, 'र': 45, 'ल': 46, 'ळ': 47, 'व': 48, 'श': 49, 'ष': 50, 'स': 51, 'ह': 52, '़': 53, 'ऽ': 54, 'ा': 55, 'ि': 56, 'ी': 57, 'ु': 58, 'ू': 59, 'ृ': 60, 'ॅ': 61, 'े': 62, 'ै': 63, 'ॉ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n"
     ]
    }
   ],
   "source": [
    "char2int_hin=char_to_int(int2char_hin)\n",
    "print(char2int_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c0f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finding the maximum sequence length'''\n",
    "length_eng=[len(i) for i in df_train['English']]\n",
    "length_hin=[len(i) for i in df_train['transliteration_in_hindi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569c1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sequence length of English words is 26\n",
      "The maximum sequence length of transliterated words is 22\n"
     ]
    }
   ],
   "source": [
    "length_eng_max=max(length_eng)+2 #we have to account for the start and end token\n",
    "print(f'The maximum sequence length of English words is {length_eng_max}')\n",
    "length_hin_max=max(length_hin)+2\n",
    "print(f'The maximum sequence length of transliterated words is {length_hin_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00064a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "num_english_tokens=len(english_vocab)\n",
    "print(num_english_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e3fabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "num_hindi_tokens=len(hindi_vocab)\n",
    "print(num_hindi_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29cd6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(length_eng_max)\n",
    "print(length_hin_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56f79e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The position of padding is zero itself, so we can create tensors using torch.zeros and proceed'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int2char_eng)\n",
    "'''The position of padding is zero itself, so we can create tensors using torch.zeros and proceed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dfa059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df['English'] = df['English'].str.lower()\n",
    "    df['transliteration_in_hindi'] = df['transliteration_in_hindi'].str.lower()\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    '''Adding start and end of word tokens'''\n",
    "    y_og = df['transliteration_in_hindi'].values\n",
    "    x_og = df['English'].values\n",
    "    x = '\\t'+x_og+'\\n'\n",
    "    y = '\\t'+y_og+'\\n'\n",
    "    y_do=y_og+'\\n'\n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    \n",
    "    enc_input_data=torch.zeros(len(x),length_eng_max)\n",
    "    dec_input_data=torch.zeros(len(y),length_hin_max)\n",
    "    dec_output_data=torch.zeros(len(y),length_hin_max)\n",
    "    for i, (xx,yy) in enumerate(zip(x,y)):\n",
    "        for j,char in enumerate(xx):\n",
    "            enc_input_data[i,j]=char2int_eng[char]\n",
    "        #pad character is zero so no need of assigning it again\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_input_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char]\n",
    "    \n",
    "    for i, (xx,yy) in enumerate(zip(x,y_do)):\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_output_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char]\n",
    "                \n",
    "    return enc_input_data,dec_input_data,dec_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e201b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    '''Adding start and end of word tokens'''\n",
    "    y = df['transliteration_in_hindi'].values\n",
    "    x= df['English'].values\n",
    "    x = '\\t'+x+'\\n'\n",
    "    y = '\\t'+y+'\\n'\n",
    "    \n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(df['English']), length_eng_max, num_english_tokens), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "    decoder_output_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "    pad_char='_'\n",
    "    for i , (input_text,target_text) in enumerate(zip(x,y)):\n",
    "        for t,char in enumerate(input_text):\n",
    "            encoder_input_data[i,t,char2int_eng[char]]=1\n",
    "        encoder_input_data[i,t+1:,char2int_eng[pad_char]]=1\n",
    "    \n",
    "        for t,char in enumerate(target_text):\n",
    "            if char in hindi_vocab:\n",
    "                decoder_input_data[i,t,char2int_hin[char]]=1\n",
    "            else:\n",
    "                decoder_input_data[i,t,char2int_hin[unknown_char]]=1\n",
    "        decoder_input_data[i,t+1:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "        '''decoder target data is one step ahead of decoder input data by one timestep\n",
    "        and doesnot includes start token'''\n",
    "        for t,char in enumerate(target_text):\n",
    "            if t>0:\n",
    "                if char in hindi_vocab:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[char]]=1\n",
    "                else:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[unknown_char]]=1\n",
    "                \n",
    "        decoder_output_data[i,t:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "    return torch.tensor(encoder_input_data),torch.tensor(decoder_input_data),torch.tensor(decoder_output_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5dcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data,dec_input_data,dec_output_data=process_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407cc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data,decoder_input_data,decoder_output_data=one_hot_encoding(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b89fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26])\n",
      "torch.Size([51200, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data.shape)\n",
    "print(dec_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9938947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26, 30])\n",
      "torch.Size([51200, 22, 68])\n",
      "torch.Size([51200, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "595cf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., 49., 51., 67., 34., 67., 45., 55., 21., 55., 45.,  2.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "print(dec_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f82c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49., 51., 67., 34., 67., 45., 55., 21., 55., 45.,  2.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "print(dec_output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee105331",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data_test,dec_input_data_test,dec_output_data_test=process_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c2e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4095, 26])\n",
      "torch.Size([4095, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data_test.shape)\n",
    "print(dec_input_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7e8f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data_val,dec_input_data_val,dec_output_data_val=process_data(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddd75195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 26])\n",
      "torch.Size([4096, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data_val.shape)\n",
    "print(dec_input_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c50840ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_test,decoder_input_data_test,decoder_output_data_test=one_hot_encoding(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13049fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4095, 26, 30])\n",
      "torch.Size([4095, 22, 68])\n",
      "torch.Size([4095, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_test.shape)\n",
    "print(decoder_input_data_test.shape)\n",
    "print(decoder_output_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d064dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_val,decoder_input_data_val,decoder_output_data_val=one_hot_encoding(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8130566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 26, 30])\n",
      "torch.Size([4096, 22, 68])\n",
      "torch.Size([4096, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)\n",
    "print(decoder_output_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31b80fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 49, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 41, 56,  ...,  0,  0,  0],\n",
      "        [ 1, 19, 56,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  7, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 51, 58,  ...,  0,  0,  0],\n",
      "        [ 1,  7,  5,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(decoder_input_data,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8987d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., 49., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 41., 56.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 19., 56.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 1.,  7., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 51., 58.,  ...,  0.,  0.,  0.],\n",
      "        [ 1.,  7.,  5.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(dec_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09800fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49, 51, 67,  ...,  0,  0,  0],\n",
      "        [41, 56, 38,  ...,  0,  0,  0],\n",
      "        [19, 56, 45,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 7, 51, 52,  ...,  0,  0,  0],\n",
      "        [51, 58, 46,  ...,  0,  0,  0],\n",
      "        [ 7,  5, 24,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(decoder_output_data,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e12e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49., 51., 67.,  ...,  0.,  0.,  0.],\n",
      "        [41., 56., 38.,  ...,  0.,  0.,  0.],\n",
      "        [19., 56., 45.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 7., 51., 52.,  ...,  0.,  0.,  0.],\n",
      "        [51., 58., 46.,  ...,  0.,  0.,  0.],\n",
      "        [ 7.,  5., 24.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(dec_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "549cb4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['transliteration_in_hindi']='\\t'+df_train['transliteration_in_hindi']+'\\n'\n",
    "df_train['English']='\\t'+df_train['English']+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30e0f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['English_seq'] = df_train['English'].apply(lambda x: [char2int_eng[char] for char in x])\n",
    "df_train['transliteration_seq'] = df_train['transliteration_in_hindi'].apply(lambda x: [char2int_hin[char] for char in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e861d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "      <th>English_seq</th>\n",
       "      <th>transliteration_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tshastragaar\\n</td>\n",
       "      <td>\\tशस्त्रागार\\n</td>\n",
       "      <td>[1, 22, 11, 4, 22, 23, 21, 4, 10, 4, 4, 21, 2]</td>\n",
       "      <td>[1, 49, 51, 67, 34, 67, 45, 55, 21, 55, 45, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\tbindhya\\n</td>\n",
       "      <td>\\tबिन्द्या\\n</td>\n",
       "      <td>[1, 5, 12, 17, 7, 11, 28, 4, 2]</td>\n",
       "      <td>[1, 41, 56, 38, 67, 36, 67, 44, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tkirankant\\n</td>\n",
       "      <td>\\tकिरणकांत\\n</td>\n",
       "      <td>[1, 14, 12, 21, 4, 17, 14, 4, 17, 23, 2]</td>\n",
       "      <td>[1, 19, 56, 45, 33, 19, 55, 5, 34, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tyagyopaveet\\n</td>\n",
       "      <td>\\tयज्ञोपवीत\\n</td>\n",
       "      <td>[1, 28, 4, 10, 28, 18, 19, 4, 25, 8, 8, 23, 2]</td>\n",
       "      <td>[1, 44, 26, 67, 28, 65, 39, 48, 57, 34, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tratania\\n</td>\n",
       "      <td>\\tरटानिया\\n</td>\n",
       "      <td>[1, 21, 4, 23, 4, 17, 12, 4, 2]</td>\n",
       "      <td>[1, 45, 29, 55, 38, 56, 44, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>\\ttoned\\n</td>\n",
       "      <td>\\tटोंड\\n</td>\n",
       "      <td>[1, 23, 18, 17, 8, 7, 2]</td>\n",
       "      <td>[1, 29, 65, 5, 31, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>\\tmutanaazaa\\n</td>\n",
       "      <td>\\tमुतनाज़ा\\n</td>\n",
       "      <td>[1, 16, 24, 23, 4, 17, 4, 4, 29, 4, 4, 2]</td>\n",
       "      <td>[1, 43, 58, 34, 38, 55, 26, 53, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>\\tasahmaton\\n</td>\n",
       "      <td>\\tअसहमतों\\n</td>\n",
       "      <td>[1, 4, 22, 4, 11, 16, 4, 23, 18, 17, 2]</td>\n",
       "      <td>[1, 7, 51, 52, 43, 34, 65, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>\\tsulgaayin\\n</td>\n",
       "      <td>\\tसुलगायीं\\n</td>\n",
       "      <td>[1, 22, 24, 15, 10, 4, 4, 28, 12, 17, 2]</td>\n",
       "      <td>[1, 51, 58, 46, 21, 55, 44, 57, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>\\tanchuthengu\\n</td>\n",
       "      <td>\\tअंचुतेंगु\\n</td>\n",
       "      <td>[1, 4, 17, 6, 11, 24, 23, 11, 8, 17, 10, 24, 2]</td>\n",
       "      <td>[1, 7, 5, 24, 58, 34, 62, 5, 21, 58, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               English transliteration_in_hindi  \\\n",
       "0      \\tshastragaar\\n           \\tशस्त्रागार\\n   \n",
       "1          \\tbindhya\\n             \\tबिन्द्या\\n   \n",
       "2        \\tkirankant\\n             \\tकिरणकांत\\n   \n",
       "3      \\tyagyopaveet\\n            \\tयज्ञोपवीत\\n   \n",
       "4          \\tratania\\n              \\tरटानिया\\n   \n",
       "...                ...                      ...   \n",
       "51195        \\ttoned\\n                 \\tटोंड\\n   \n",
       "51196   \\tmutanaazaa\\n             \\tमुतनाज़ा\\n   \n",
       "51197    \\tasahmaton\\n              \\tअसहमतों\\n   \n",
       "51198    \\tsulgaayin\\n             \\tसुलगायीं\\n   \n",
       "51199  \\tanchuthengu\\n            \\tअंचुतेंगु\\n   \n",
       "\n",
       "                                           English_seq  \\\n",
       "0       [1, 22, 11, 4, 22, 23, 21, 4, 10, 4, 4, 21, 2]   \n",
       "1                      [1, 5, 12, 17, 7, 11, 28, 4, 2]   \n",
       "2             [1, 14, 12, 21, 4, 17, 14, 4, 17, 23, 2]   \n",
       "3       [1, 28, 4, 10, 28, 18, 19, 4, 25, 8, 8, 23, 2]   \n",
       "4                      [1, 21, 4, 23, 4, 17, 12, 4, 2]   \n",
       "...                                                ...   \n",
       "51195                         [1, 23, 18, 17, 8, 7, 2]   \n",
       "51196        [1, 16, 24, 23, 4, 17, 4, 4, 29, 4, 4, 2]   \n",
       "51197          [1, 4, 22, 4, 11, 16, 4, 23, 18, 17, 2]   \n",
       "51198         [1, 22, 24, 15, 10, 4, 4, 28, 12, 17, 2]   \n",
       "51199  [1, 4, 17, 6, 11, 24, 23, 11, 8, 17, 10, 24, 2]   \n",
       "\n",
       "                                  transliteration_seq  \n",
       "0      [1, 49, 51, 67, 34, 67, 45, 55, 21, 55, 45, 2]  \n",
       "1              [1, 41, 56, 38, 67, 36, 67, 44, 55, 2]  \n",
       "2               [1, 19, 56, 45, 33, 19, 55, 5, 34, 2]  \n",
       "3          [1, 44, 26, 67, 28, 65, 39, 48, 57, 34, 2]  \n",
       "4                  [1, 45, 29, 55, 38, 56, 44, 55, 2]  \n",
       "...                                               ...  \n",
       "51195                           [1, 29, 65, 5, 31, 2]  \n",
       "51196          [1, 43, 58, 34, 38, 55, 26, 53, 55, 2]  \n",
       "51197                [1, 7, 51, 52, 43, 34, 65, 5, 2]  \n",
       "51198           [1, 51, 58, 46, 21, 55, 44, 57, 5, 2]  \n",
       "51199         [1, 7, 5, 24, 58, 34, 62, 5, 21, 58, 2]  \n",
       "\n",
       "[51200 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22627fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data=enc_input_data.long()\n",
    "dec_input_data=dec_input_data.long()\n",
    "enc_input_data_test=enc_input_data_test.long()\n",
    "dec_input_data_test=dec_input_data_test.long()\n",
    "enc_input_data_val=enc_input_data_val.long()\n",
    "dec_input_data_val=dec_input_data_val.long()\n",
    "encoder_input_data=encoder_input_data.long()\n",
    "decoder_input_data=decoder_input_data.long()\n",
    "decoder_output_data=decoder_output_data.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0235c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_word_accuracy(dec_predicted_data, dec_output_data):\n",
    "#     #Here, we have to pass the arguments in the shape(batch_size,sequence_length)\n",
    "#     batch_size = dec_predicted_data.shape[0]\n",
    "#     dec_predicted_data=torch.argmax(dec_predicted_data,dim=-1)\n",
    "#     dec_output_data=torch.argmax(dec_output_data,dim=-1)\n",
    "#     with torch.no_grad():\n",
    "#         true_words = 0\n",
    "#         for i in range(batch_size):\n",
    "#             mark = True\n",
    "#             for j in range(dec_predicted_data.shape[1]):\n",
    "#                 if dec_predicted_data[i, j] == dec_output_data[i, j]:\n",
    "#                     mark = True\n",
    "#                 else:\n",
    "#                     mark = False\n",
    "#                     break\n",
    "#             if mark == True:\n",
    "#                 true_words =true_words+ 1\n",
    "#     return (true_words / batch_size)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d756511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_accuracy(dec_predicted_data, dec_output_data):\n",
    "    # Here, we have to pass the arguments in the shape (batch_size, sequence_length)\n",
    "    dec_predicted_data = torch.argmax(dec_predicted_data, dim=-1)\n",
    "    dec_output_data = torch.argmax(dec_output_data, dim=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        match = (dec_predicted_data == dec_output_data).all(dim=1)\n",
    "        true_words = match.sum().item()\n",
    "        batch_size = dec_predicted_data.shape[0]\n",
    "    \n",
    "    accuracy = (true_words / batch_size) * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e1a52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_acc=calculate_word_accuracy(decoder_input_data,decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd3abf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(word_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1428344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_char_accuracy(decoder_predicted_data, decoder_output_data):\n",
    "    #Here, we have to pass the arguments in the shape(batch_size,sequence_length,unique_tokens)\n",
    "    batch_size, seq_length,unique_tokens = decoder_predicted_data.shape\n",
    "    dec_predicted_data=torch.argmax(decoder_predicted_data,dim=-1)\n",
    "    dec_output_data=torch.argmax(decoder_output_data,dim=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_count = (dec_predicted_data == dec_output_data).sum().item()\n",
    "        return (correct_count / (seq_length * batch_size))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01bdebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_accuracy = calculate_char_accuracy(decoder_input_data[7:9,:,:],decoder_input_data[1:3,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a66732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.36363636363637\n"
     ]
    }
   ],
   "source": [
    "print(char_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ea2b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens_eng=len(english_vocab)\n",
    "unique_tokens_hin=len(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1287bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(x,y,z,batch_size,device=device):\n",
    "    \n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    z=z.to(device)\n",
    "    combined=TensorDataset(x,y,z)\n",
    "    loader=DataLoader(combined,batch_size=batch_size,shuffle=False,drop_last=True)#required in test data\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "661d9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07817af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_dim, drop_out, bi_dir, cell,unique_tokens_eng):\n",
    "        '''unique_token_hin is the third dimension in one hot encoding or no of tokens in eng or input size'''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.unique_tokens_eng=unique_tokens_eng\n",
    "        self.embed_dim=embed_dim\n",
    "        self.drop_out=drop_out\n",
    "        '''The input to the encoder will be of shape (batch_size,sequence_length) and the output size will be\n",
    "        (batch_size,seq_length,embed_size)'''\n",
    "        self.dropout=nn.Dropout(p=self.drop_out)\n",
    "\n",
    "        self.embedding = nn.Embedding(unique_tokens_eng, embed_dim, padding_idx=0) \n",
    "        \n",
    "        self.rnn=nn.RNN(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.gru=nn.GRU(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.lstm=nn.LSTM(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                         num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "\n",
    "    def forward(self, x,hidden):\n",
    "        '''Here, x is the encoder input data'''\n",
    "        batch_size=x.size(0)\n",
    "        x=x.to(device)\n",
    "        embedding_input = self.embedding(x.long())\n",
    "        embedding_input = self.dropout(embedding_input)\n",
    "        #print(embedding_input.shape)\n",
    "#         if self.cell == \"LSTM\":\n",
    "#             h_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "#             c_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)  \n",
    "#         else:\n",
    "#             h_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "              \n",
    "        if self.cell==\"GRU\":\n",
    "            output,h_n=self.gru(embedding_input,hidden)#h_0.detach())\n",
    "            #print(output.shape)\n",
    "            #print(h_n.shape)\n",
    "            return output,h_n\n",
    "        elif self.cell=='RNN':\n",
    "            output,h_n=self.gru(embedding_input,hidden)#.detach())\n",
    "            #print(output.shape)\n",
    "            #print(h_n.shape)\n",
    "            return output,h_n\n",
    "        elif self.cell=='LSTM':\n",
    "            output,(h_n,c_n)=self.lstm(embedding_input,hidden)\n",
    "            #(h_0.detach(),c_0.detach()))\n",
    "            #print(output.shape)\n",
    "            #print(h_n.shape)\n",
    "            #print(c_n.shape)\n",
    "            return output,(h_n,c_n)\n",
    "            \n",
    "    def encoder_initial(self,batch_size,device=device):\n",
    "        if self.cell == \"LSTM\":\n",
    "            h_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            c_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device) \n",
    "            return (h_0,c_0)\n",
    "        #H_0,C_0 HAVE SAME DIMENSION\n",
    "        else:\n",
    "            h_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            return h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f55ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder_attention(nn.Module):\n",
    "#     def __init__(self, embed_dim, hidden_dim, layer_dim, drop_out, bi_dir, cell,\n",
    "#                  unique_tokens_hin, input_length,target_length):\n",
    "#         '''unique_token_hin is the third dimension in one hot encoding or no of tokens in hindi or output size'''\n",
    "#         #input_length is the sequence length of encoder input(english)\n",
    "#         super(Decoder_attention, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.layer_dim = layer_dim\n",
    "#         self.cell = cell\n",
    "#         self.bi_dir = bi_dir\n",
    "#         self.unique_tokens_hin = unique_tokens_hin\n",
    "#         self.embed_dim = embed_dim\n",
    "#         self.drop_out = drop_out\n",
    "#         self.input_length = input_length\n",
    "#         self.target_length=target_length\n",
    "        \n",
    "#         self.embedding = nn.Embedding(unique_tokens_hin, embed_dim, padding_idx=0)\n",
    "#         self.dropout = nn.Dropout(p=self.drop_out)\n",
    "#         self.UattnSt_1 = nn.Linear(hidden_dim*(int(self.bi_dir)+1),hidden_dim*(int(self.bi_dir)+1)) #St-1 is of shape (num_layers(1+D),batch_size,hidden_dim),which should be \n",
    "#         #converted into (batch_size,1,hidden_dim). So ,either reshape it accordingly or take it from decoder rnn\n",
    "#         #output; not after softmax.output after this:(batch_size,1,hidden_dim)\n",
    "#         self.Wattnh_j = nn.Linear(hidden_dim*(int(self.bi_dir)+1),hidden_dim*(int(self.bi_dir)+1))#h_j contains all the encoder hidden states,taken from encoder outputs, which is \n",
    "#         #of shape(batch_size,input_tokens,hidden_dim).output(batch_size,input_tokens,hidden_dim)\n",
    "#         self.tanh = nn.Tanh()\n",
    "#         self.e_jt = nn.Linear(hidden_dim*(int(self.bi_dir)+1),1)#Vattn.T process is performed.Output gives attention score of shape\n",
    "#         #(batch_size,input_tokens,1).\n",
    "#         self.alpha_jt=nn.Softmax(dim=-1)\n",
    "#         self.rnn = nn.RNN(self.embed_dim + hidden_dim*(int(self.bi_dir)+1) , hidden_dim,\n",
    "#                     num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "#         self.gru = nn.GRU(self.embed_dim + hidden_dim*(int(self.bi_dir)+1) , hidden_dim,\n",
    "#                     num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "#         self.lstm = nn.LSTM(self.embed_dim + hidden_dim*(int(self.bi_dir)+1), hidden_dim,\n",
    "#                     num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.out_put = nn.Linear((1 + int(self.bi_dir)) * self.hidden_dim, self.unique_tokens_hin)\n",
    "#         self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, x, hidden, encoder_outputs):\n",
    "#         batch_size = x.size(0)\n",
    "#         x=x.to(device)\n",
    "#         embedding_output = self.embedding(x.long())\n",
    "#         embedding_output=embedding_output.to(device)\n",
    "#         embedding_output = self.dropout(embedding_output)\n",
    "#         #print('hidden[0]',hidden[0].shape)\n",
    "#         if self.bi_dir == False:\n",
    "#             if self.cell == 'LSTM':\n",
    "#                 st_1=torch.mean(hidden[0],dim=0,keepdim=True).squeeze(dim=0).unsqueeze(dim=1)\n",
    "#                 #print('st1 initial',st_1.shape)\n",
    "#             else:\n",
    "#                 st_1=torch.mean(hidden,dim=0,keepdim=True).squeeze(dim=0).unsqueeze(dim=1)\n",
    "                \n",
    "#         elif self.bi_dir == True: # encoorporates for multiple layers and bidirection\n",
    "#             if self.cell == 'LSTM':\n",
    "#                 h=hidden[0]\n",
    "#                 h_forward = h[:self.layer_dim]\n",
    "#                 h_backward=h[self.layer_dim:]\n",
    "#                 h=torch.cat((h_forward,h_backward),dim=-1)\n",
    "#                 h=torch.mean(h,dim=0,keepdim=True)\n",
    "#                 st_1=h.squeeze(dim=0).unsqueeze(dim=1)\n",
    "#             else:\n",
    "#                 h=hidden\n",
    "#                 h_forward = h[:self.layer_dim]\n",
    "#                 h_backward=h[self.layer_dim:]\n",
    "#                 #print(h_forward.shape)\n",
    "#                 #print(h_backward.shape)\n",
    "#                 h=torch.cat((h_forward,h_backward),dim=-1)\n",
    "#                 h=torch.mean(h,dim=0,keepdim=True)\n",
    "#                 st_1=h.squeeze(dim=0).unsqueeze(dim=1)\n",
    "                \n",
    "        \n",
    "#         #print('st1 final',st_1.shape)\n",
    "#         a = self.UattnSt_1(st_1) \n",
    "#         b = self.Wattnh_j(encoder_outputs)\n",
    "#         #print('a',a.shape)\n",
    "#         #print('b',b.shape)\n",
    "#         att=a+b\n",
    "#         att=self.tanh(att)\n",
    "#         attention_score = self.e_jt(att)\n",
    "#         attention_weights=self.alpha_jt(attention_score)#each column consists of one words' att. weights\n",
    "#         attention_weights = attention_weights.squeeze(dim=-1)\n",
    "#         attention_weights = attention_weights.unsqueeze(dim=1)#Now,each row consists of one words' att. weights\n",
    "#         context = torch.bmm(attention_weights,encoder_outputs)\n",
    "#         #print('context',context.shape)\n",
    "#         #print('emb',embedding_output.shape)\n",
    "#         concatenated_output = torch.cat((embedding_output, context), dim=2)\n",
    "#         #(batch_size,1,embed_dim+hidden_dim)\n",
    "#         #concatenated_output =self.relu(concatenated_output)\n",
    "#         #print('ip',concatenated_output.shape)\n",
    "\n",
    "#         if self.cell==\"GRU\":\n",
    "#             output,h_n=self.gru(concatenated_output,hidden)#.detach())\n",
    "#             output = self.softmax(self.out_put(output))\n",
    "#             return output,h_n,attention_weights\n",
    "#             #print(output.shape)\n",
    "#             #print(h_n.shape)\n",
    "#         elif self.cell=='RNN':\n",
    "#             output,h_n=self.gru(concatenated_output,hidden)#.detach())\n",
    "#             return output,h_n,attention_weights\n",
    "#             #print(output.shape)\n",
    "#             #print(h_n.shape)\n",
    "#         elif self.cell=='LSTM':\n",
    "#             output,(h_n,c_n)=self.lstm(concatenated_output,hidden)\n",
    "#             output = self.softmax(self.out_put(output))\n",
    "#             return output,(h_n,c_n),attention_weights\n",
    "#             #(h_0.detach(),c_0.detach()))\n",
    "#             #print(output.shape)\n",
    "#             #print(h_n.shape)\n",
    "#             #print(c_n.shape)\n",
    "#         #print(output.shape)\n",
    "        \n",
    "#         #print(output.shape)\n",
    "#         #print('hi')\n",
    "            \n",
    "\n",
    "#     def decoder_attn_initial(self, batch_size, device=device):\n",
    "#         if self.cell == \"LSTM\":\n",
    "#             h_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "#             c_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "#             return (h_0,c_0)\n",
    "#         else:\n",
    "#             h_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "#             return h_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2103d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_attention(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_dim, drop_out, bi_dir, cell,\n",
    "                 unique_tokens_hin, input_length,target_length):\n",
    "        '''unique_token_hin is the third dimension in one hot encoding or no of tokens in hindi or output size'''\n",
    "        #input_length is the sequence length of encoder input(english)\n",
    "        super(Decoder_attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.unique_tokens_hin = unique_tokens_hin\n",
    "        self.embed_dim = embed_dim\n",
    "        self.drop_out = drop_out\n",
    "        self.input_length = input_length\n",
    "        self.target_length=target_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(unique_tokens_hin, embed_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(p=self.drop_out)\n",
    "        self.UattnSt_1 = nn.Linear(hidden_dim,hidden_dim) \n",
    "        self.Wattnh_j = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.e_jt = nn.Linear(hidden_dim,1)\n",
    "        self.alpha_jt=nn.Softmax(dim=2)\n",
    "        self.rnn = nn.RNN(self.embed_dim + hidden_dim*layer_dim*(1+int(bi_dir)) , hidden_dim,\n",
    "                    num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "        self.gru = nn.GRU(self.embed_dim + hidden_dim*layer_dim*(1+int(bi_dir)) , hidden_dim,\n",
    "                    num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "        self.lstm = nn.LSTM(self.embed_dim + hidden_dim*layer_dim*(1+int(bi_dir)), hidden_dim,\n",
    "                    num_layers=self.layer_dim, batch_first=True, bidirectional=self.bi_dir, dropout=self.drop_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_put = nn.Linear((1 + int(self.bi_dir)) * self.hidden_dim, self.unique_tokens_hin)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        batch_size = x.size(0)\n",
    "        x=x.to(device)\n",
    "        embedding_output = self.embedding(x.long())\n",
    "        embedding_output=embedding_output.to(device)\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "       \n",
    "        if self.cell =='LSTM':\n",
    "            st_1 = hidden[0].unsqueeze(dim=2)\n",
    "        else:\n",
    "            st_1 = hidden.unsqueeze(dim=2)\n",
    "            \n",
    "        a = self.UattnSt_1(st_1) \n",
    "        b = self.Wattnh_j(encoder_outputs)\n",
    "\n",
    "        att=a+b\n",
    "        att=self.tanh(att)\n",
    "        attention_score = self.e_jt(att)\n",
    "        attention_weights=self.alpha_jt(attention_score)\n",
    "        attention_weights = attention_weights.squeeze(dim=-1)\n",
    "        attention_weights = attention_weights.unsqueeze(dim=2)\n",
    "        attention_weights = attention_weights.squeeze(-1).unsqueeze(1)\n",
    "        context = torch.zeros(self.layer_dim*(1+int(self.bi_dir)),batch_size,1,self.hidden_dim)\n",
    "        for i in range(context.shape[0]):\n",
    "    \n",
    "            \n",
    "            context[i,:,:,:] = torch.bmm(attention_weights[i].squeeze(0),encoder_outputs[i].squeeze(0))\n",
    "    \n",
    "\n",
    "        context = context.reshape(batch_size,self.hidden_dim*(1+int(self.bi_dir))*self.layer_dim)\n",
    "        context = context.unsqueeze(1)\n",
    "    \n",
    "        context=context.to(device)\n",
    "        concatenated_output = torch.cat((embedding_output, context), dim=2)\n",
    "        #(batch_size,1,embed_dim+hidden_dim)\n",
    "        concatenated_output =self.relu(concatenated_output)\n",
    "\n",
    "\n",
    "        if self.cell==\"GRU\":\n",
    "            output,h_n=self.gru(concatenated_output,hidden)#.detach())\n",
    "            output = self.softmax(self.out_put(output))\n",
    "            return output,h_n,attention_weights\n",
    "           \n",
    "        elif self.cell=='RNN':\n",
    "            output,h_n=self.gru(concatenated_output,hidden)#.detach())\n",
    "            return output,h_n,attention_weights\n",
    "            \n",
    "        elif self.cell=='LSTM':\n",
    "            output,(h_n,c_n)=self.lstm(concatenated_output,hidden)\n",
    "            output = self.softmax(self.out_put(output))\n",
    "            return output,(h_n,c_n),attention_weights\n",
    "            \n",
    "            \n",
    "\n",
    "    def decoder_attn_initial(self, batch_size, device=device):\n",
    "        if self.cell == \"LSTM\":\n",
    "            h_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "            c_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "            return (h_0,c_0)\n",
    "        else:\n",
    "            h_0 = torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim,device=device)\n",
    "            return h_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ce055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To use when the number of encoder and decoder layers are different'''\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, num_enc_layers, num_dec_layers, cell, bi_dir):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.num_enc_layers = num_enc_layers\n",
    "        self.num_dec_layers = num_dec_layers\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.linear = nn.Linear(num_enc_layers * int(1 + bi_dir), num_dec_layers * int(1 + bi_dir))\n",
    "\n",
    "    def forward(self, h_n_enc):\n",
    "        if self.cell == 'LSTM':\n",
    "            x=x.permute(*torch.arange(x.ndim - 1, -1, -1))\n",
    "            h_dec = self.linear(h_n_enc[0].permute(*torch.arange(h_n_enc.ndim - 1, -1, -1)))\n",
    "            c_dec = self.linear(h_n_enc[1].permute(*torch.arange(c_n_enc.ndim - 1, -1, -1)))\n",
    "            h_0_dec = (h_dec.permute(*torch.arange(h_dec.ndim - 1, -1, -1)),\n",
    "                       c_dec.permute(*torch.arange(c_dec.ndim - 1, -1, -1)))\n",
    "        else:\n",
    "            h_0_dec = self.linear(h_n_enc.permute(*torch.arange(h_n_enc.ndim - 1, -1, -1)))\n",
    "            h_0_dec = h_0_dec.permute(*torch.arange(h_0_dec.ndim - 1, -1, -1))\n",
    "        return h_0_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e8fbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(input_tensor, target_tensor,target_onehot, encoder_model, decoder_model, encoder_optimizer,\n",
    "          decoder_optimizer,hidden_dim,criterion,input_length,target_length,batch_size,\n",
    "             teacher_forcing_ratio,layer_dim,bi_dir,cell,reshape,ropt,device=device):\n",
    "    \n",
    "    \n",
    "    h_0_enc = encoder_model.encoder_initial(batch_size)\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #ropt.zero_grad()\n",
    "    uh=target_onehot.shape[-1]\n",
    "    decoder_predicted=torch.zeros(batch_size,target_length,uh,device=device)\n",
    "    loss = 0\n",
    "    encoder_outputs = torch.zeros(layer_dim * (1 + int(bi_dir)), batch_size, input_length, hidden_dim, device=device)\n",
    "    \n",
    "    encoder_model.train()\n",
    "    decoder_model.train()\n",
    "    #reshape.train()\n",
    "    \n",
    "    '''Encoder model is given and the representation of input word is taken from it'''\n",
    "    for i in range(input_length):\n",
    "        output_enc, h_n_enc = encoder_model(input_tensor[:,i].unsqueeze(1), h_0_enc)\n",
    "        if cell =='LSTM':\n",
    "            encoder_outputs[:,:,i:i+1,:]  = h_n_enc[0].unsqueeze(2)\n",
    "        else:\n",
    "             encoder_outputs[:,:,i:i+1,:]  = h_n_enc.unsqueeze(2)\n",
    "            \n",
    "        h_0_enc=h_n_enc\n",
    "\n",
    "    dec_input = torch.ones(batch_size,1,device=device)#start token is given as the input and the indices is 1.\n",
    "    #h_0_dec=reshape(h_n_enc)\n",
    "    h_0_dec=h_n_enc\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(target_length):\n",
    "            output_dec, h_n_dec,attention_weights = decoder_model(dec_input, h_0_dec,encoder_outputs)\n",
    "            decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "            loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "            #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "            dec_input = target_tensor[:,i].unsqueeze(1)  # Teacher forcing\n",
    "            h_0_dec = h_n_dec\n",
    "            \n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(target_length):\n",
    "            output_dec, h_n_dec,attention_weights = decoder_model(dec_input, h_0_dec,encoder_outputs)\n",
    "            #top_values, top_indices = output_dec.topk(k=1, dim=2)\n",
    "            #dec_input = top_indices.view(-1,1).detach()# detach from history as input\n",
    "            dec_input = torch.argmax(output_dec,dim=-1)\n",
    "            decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "            loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "            #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "            h_0_dec=h_n_dec\n",
    "    \n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #ropt.step()\n",
    "    \n",
    "    loss_batch = loss.item() / target_length\n",
    "    char_acc_batch = calculate_char_accuracy(decoder_predicted,target_onehot)\n",
    "    word_acc_batch = calculate_word_accuracy(decoder_predicted,target_onehot)\n",
    "    return loss_batch, char_acc_batch, word_acc_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "239ffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(input_tensor, target_tensor,target_onehot, encoder_model, decoder_model,\n",
    "          hidden_dim,criterion,input_length,target_length,batch_size,\n",
    "             layer_dim,bi_dir,cell,reshape,device=device):\n",
    "    \n",
    "    encoder_outputs = torch.zeros(layer_dim * (1 + int(bi_dir)), batch_size, input_length, hidden_dim, device=device)\n",
    "    h_0_enc = encoder_model.encoder_initial(batch_size)\n",
    "    uh=target_onehot.shape[-1]\n",
    "    decoder_predicted=torch.zeros(batch_size,target_length,uh,device=device)\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_model.eval()\n",
    "    decoder_model.eval()\n",
    "    #reshape.eval()\n",
    "    #print('hi')\n",
    "    '''Encoder model is given and the representation of input word is taken from it'''\n",
    "    for i in range(input_length):\n",
    "        output_enc, h_n_enc = encoder_model(input_tensor[:,i].unsqueeze(1), h_0_enc)\n",
    "        \n",
    "        if cell =='LSTM':\n",
    "            encoder_outputs[:,:,i:i+1,:]  = h_n_enc[0].unsqueeze(2)\n",
    "        else:\n",
    "             encoder_outputs[:,:,i:i+1,:]  = h_n_enc.unsqueeze(2)\n",
    "        h_0_enc=h_n_enc\n",
    "\n",
    "    dec_input = torch.ones(batch_size,1,device=device)#start token is given as the input and the indices is 1.\n",
    "    #h_0_dec=reshape(h_n_enc)\n",
    "    h_0_dec=h_n_enc\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for i in range(target_length):\n",
    "        output_dec, h_n_dec, attention_weights= decoder_model(dec_input, h_0_dec,encoder_outputs)\n",
    "        #top_values, top_indices = output_dec.topk(k=1, dim=2)\n",
    "        #dec_input = top_indices.view(-1,1).detach()# detach from history as input\n",
    "        dec_input = torch.argmax(output_dec,dim=-1)\n",
    "        decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "        h_0_dec=h_n_dec\n",
    "        loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "        #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "    \n",
    "    loss_batch = loss.item() / target_length\n",
    "    char_acc_batch = calculate_char_accuracy(decoder_predicted,target_onehot)\n",
    "    word_acc_batch = calculate_word_accuracy(decoder_predicted,target_onehot)\n",
    "    return loss_batch, char_acc_batch, word_acc_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44469cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x=enc_input_data,y=dec_output_data,yonehot=decoder_output_data,\n",
    "          x_val=enc_input_data_val,y_val=dec_output_data_val,yonehot_val=decoder_output_data_val,\n",
    "          epochs=10,optimizer='Adam',learning_rate=0.01,weight_decay=0.0001,layer_dim=1,bi_dir=False,\n",
    "          teacher_forcing_ratio=0.5,cell='LSTM',embed_dim=128,hidden_dim=128,batch_size=64,drop_out=0.3):\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    input_length = x.shape[1]\n",
    "    target_length = y.shape[1]\n",
    "    num_enc_layers=layer_dim\n",
    "    num_dec_layers=layer_dim\n",
    "    \n",
    "    encoder_model = Encoder(embed_dim, hidden_dim, num_enc_layers, drop_out, bi_dir, cell,unique_tokens_eng).to(device)\n",
    "    decoder_model = Decoder_attention(embed_dim, hidden_dim,layer_dim,drop_out,bi_dir,cell,unique_tokens_hin,\n",
    "                                      input_length,target_length).to(device)\n",
    "    reshape=Reshape(num_enc_layers, num_dec_layers, cell, bi_dir).to(device)\n",
    "    if optimizer=='Adam':\n",
    "        encoder_optimizer=torch.optim.Adam(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.Adam(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.Adam(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    elif optimizer=='NAdam':\n",
    "        encoder_optimizer=torch.optim.NAdam(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.NAdam(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.NAdam(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    elif optimizer=='SGD':\n",
    "        \n",
    "        encoder_optimizer=torch.optim.SGD(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.SGD(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.SGD(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        \n",
    "    train_loader = data_loader(x,y,yonehot,batch_size,device=device)\n",
    "    val_loader = data_loader(x_val,y_val,yonehot_val,batch_size,device=device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion=nn.NLLLoss()\n",
    "    \n",
    "    epoch_losses=[]\n",
    "    epoch_char_accuracy=[]\n",
    "    epoch_word_accuracy=[]\n",
    "    epoch_losses_val=[]\n",
    "    epoch_char_accuracy_val=[]\n",
    "    epoch_word_accuracy_val=[]\n",
    "    \n",
    "    for i in range(1, epochs + 1):\n",
    "        batch_losses=[]\n",
    "        batch_char_acc=[]\n",
    "        batch_word_acc=[]\n",
    "        batch_losses_val=[]\n",
    "        batch_char_acc_val=[]\n",
    "        batch_word_acc_val=[]\n",
    "        for enc_input_tensor,dec_target_tensor,dec_onehot in train_loader:\n",
    "            \n",
    "            loss_batch,char_acc_batch,word_acc_batch = gradient(enc_input_tensor,dec_target_tensor,dec_onehot,\n",
    "                    encoder_model,decoder_model,encoder_optimizer,decoder_optimizer,\n",
    "                    hidden_dim,criterion,input_length,target_length,batch_size, teacher_forcing_ratio,\n",
    "                            layer_dim,bi_dir,cell,reshape,ropt,device=device)\n",
    "            \n",
    "        for enc_input_tensor_val,dec_target_tensor_val,dec_onehot_val in val_loader: \n",
    "            \n",
    "            loss_batch_val,char_acc_batch_val,word_acc_batch_val=testing(enc_input_tensor_val,dec_target_tensor_val,\n",
    "                        dec_onehot_val,encoder_model,decoder_model,hidden_dim,criterion,input_length,\n",
    "                        target_length,batch_size,layer_dim,bi_dir,cell,reshape,device=device)\n",
    "          \n",
    "            batch_losses.append(loss_batch)\n",
    "            batch_char_acc.append(char_acc_batch)\n",
    "            batch_word_acc.append(word_acc_batch)\n",
    "            batch_losses_val.append(loss_batch_val)\n",
    "            batch_char_acc_val.append(char_acc_batch_val)\n",
    "            batch_word_acc_val.append(word_acc_batch_val)\n",
    "            \n",
    "            \n",
    "        epoch_loss=sum(batch_losses)/len(batch_losses)\n",
    "        epoch_char_acc=sum(batch_char_acc)/len(batch_char_acc)\n",
    "        epoch_word_acc=sum(batch_word_acc)/len(batch_word_acc)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_char_accuracy.append(epoch_char_acc)\n",
    "        epoch_word_accuracy.append(epoch_word_acc)\n",
    "        \n",
    "        epoch_loss_val = sum(batch_losses_val) / len(batch_losses_val)\n",
    "        epoch_char_acc_val = sum(batch_char_acc_val) / len(batch_char_acc_val)\n",
    "        epoch_word_acc_val = sum(batch_word_acc_val) / len(batch_word_acc_val)\n",
    "        epoch_losses_val.append(epoch_loss_val)\n",
    "        epoch_char_accuracy_val.append(epoch_char_acc_val)\n",
    "        epoch_word_accuracy_val.append(epoch_word_acc_val)\n",
    "        \n",
    "        #wandb.log({'train_loss': epoch_loss, 'train_char_acc': epoch_char_acc, 'train_word_acc': epoch_word_acc, 'valid_loss': epoch_loss_val, 'valid_char_acc': epoch_char_acc_val, 'valid_word_acc': epoch_word_acc_val})\n",
    "        print(f'{timeSince(start, i / epochs)} ({i} {i / epochs * 100:.2f}%) Trainloss: {epoch_losses[-1]:.4f} Char Accuracy: {epoch_char_accuracy[-1]:.4f} Word Accuracy: {epoch_word_accuracy[-1]:.4f}')\n",
    "        print(f'{timeSince(start, i / epochs)} ({i} {i / epochs * 100:.2f}%) Validationloss: {epoch_losses_val[-1]:.4f} Char Accuracy: {epoch_char_accuracy_val[-1]:.4f} Word Accuracy: {epoch_word_accuracy_val[-1]:.4f}')\n",
    "\n",
    "\n",
    "    return encoder_model,decoder_model,encoder_optimizer,decoder_optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8888d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoder_model,decoder_model,encoder_optimizer,decoder_optimizer=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7cf92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample wandb run()\n",
    "def wandb_run():\n",
    "    \n",
    "    config_defaults = {\n",
    "        'optimizer': 'Adam',\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 10,\n",
    "        'hidden_dim': 512,\n",
    "        'embed_dim': 512,\n",
    "        'layer_dim': 2,\n",
    "        'drop_out': 0.3,\n",
    "        'cell': 'GRU',\n",
    "        'weight_decay': 0.001,\n",
    "        'bi_dir': True,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    run_name = f'lr_{config.learning_rate}_acti_{config.optimizer}_epochs_{config.epochs}_cell_{config.cell}_dir_{config.bi_dir}_num_hid_{config.hidden_dim}_ld_{config.layer_dim}_ed_{config.embed_dim}__drop__{config.drop_out}'\n",
    "    print(run_name)\n",
    "    wandb.init(name=run_name)\n",
    "    encoder_model, decoder_model, encoder_optimizer, decoder_optimizer = train(\n",
    "        x=enc_input_data,\n",
    "        y=dec_output_data,\n",
    "        yonehot=decoder_output_data,\n",
    "        x_val=enc_input_data_val,\n",
    "        y_val=dec_output_data_val,\n",
    "        yonehot_val=decoder_output_data_val,\n",
    "        epochs=config.epochs,\n",
    "        optimizer=config.optimizer,\n",
    "        learning_rate=config.learning_rate,\n",
    "        weight_decay=config.weight_decay,\n",
    "        layer_dim=config.layer_dim,\n",
    "        bi_dir=config.bi_dir,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        cell=config.cell,\n",
    "        embed_dim=config.embed_dim,\n",
    "        hidden_dim=config.hidden_dim,\n",
    "        batch_size=config.batch_size,\n",
    "        drop_out=config.drop_out\n",
    "    )\n",
    "     \n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1102ca78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: t4jo8lzu\n",
      "Sweep URL: https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9fptv89m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_164417-9fptv89m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">expert-sweep-1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_False_num_hid_512_ld_1_ed_512__drop__0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9fptv89m) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_164417-9fptv89m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9fptv89m). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6a68025d1d41aba502f72164e7bf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666960228321841, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_164424-9fptv89m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_False_num_hid_512_ld_1_ed_512__drop__0.1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agcl/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 27s (- 4m 9s) (1 10.00%) Trainloss: 0.6172 Char Accuracy: 80.8239 Word Accuracy: 10.1562\n",
      "0m 27s (- 4m 9s) (1 10.00%) Validationloss: 0.5126 Char Accuracy: 83.4573 Word Accuracy: 11.7432\n",
      "0m 53s (- 3m 34s) (2 20.00%) Trainloss: 0.4726 Char Accuracy: 85.0142 Word Accuracy: 17.9688\n",
      "0m 53s (- 3m 34s) (2 20.00%) Validationloss: 0.4281 Char Accuracy: 86.0307 Word Accuracy: 24.2676\n",
      "1m 19s (- 3m 5s) (3 30.00%) Trainloss: 0.1975 Char Accuracy: 94.8153 Word Accuracy: 32.0312\n",
      "1m 19s (- 3m 5s) (3 30.00%) Validationloss: 0.4264 Char Accuracy: 87.0683 Word Accuracy: 30.6641\n",
      "1m 45s (- 2m 37s) (4 40.00%) Trainloss: 0.1711 Char Accuracy: 95.2415 Word Accuracy: 32.8125\n",
      "1m 45s (- 2m 37s) (4 40.00%) Validationloss: 0.4101 Char Accuracy: 87.6620 Word Accuracy: 33.1299\n",
      "2m 10s (- 2m 10s) (5 50.00%) Trainloss: 0.3774 Char Accuracy: 87.8196 Word Accuracy: 35.9375\n",
      "2m 10s (- 2m 10s) (5 50.00%) Validationloss: 0.3707 Char Accuracy: 88.0771 Word Accuracy: 32.8613\n",
      "2m 37s (- 1m 44s) (6 60.00%) Trainloss: 0.1635 Char Accuracy: 95.5611 Word Accuracy: 38.2812\n",
      "2m 37s (- 1m 44s) (6 60.00%) Validationloss: 0.3897 Char Accuracy: 88.0271 Word Accuracy: 34.7656\n",
      "3m 3s (- 1m 18s) (7 70.00%) Trainloss: 0.3957 Char Accuracy: 87.7486 Word Accuracy: 36.7188\n",
      "3m 3s (- 1m 18s) (7 70.00%) Validationloss: 0.3799 Char Accuracy: 87.7253 Word Accuracy: 32.0068\n",
      "3m 30s (- 0m 52s) (8 80.00%) Trainloss: 0.3486 Char Accuracy: 89.9148 Word Accuracy: 45.3125\n",
      "3m 30s (- 0m 52s) (8 80.00%) Validationloss: 0.3770 Char Accuracy: 88.4055 Word Accuracy: 36.2549\n",
      "3m 58s (- 0m 26s) (9 90.00%) Trainloss: 0.1420 Char Accuracy: 96.0938 Word Accuracy: 42.1875\n",
      "3m 58s (- 0m 26s) (9 90.00%) Validationloss: 0.3919 Char Accuracy: 88.6020 Word Accuracy: 37.4512\n",
      "4m 25s (- 0m 0s) (10 100.00%) Trainloss: 0.1509 Char Accuracy: 96.0227 Word Accuracy: 45.3125\n",
      "4m 25s (- 0m 0s) (10 100.00%) Validationloss: 0.3766 Char Accuracy: 88.6808 Word Accuracy: 36.9629\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_False_num_hid_512_ld_1_ed_512__drop__0.1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/9fptv89m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_164424-9fptv89m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g2fee6e6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_164922-g2fee6e6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">stellar-sweep-2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.01_acti_NAdam_epochs_10_cell_GRU_dir_False_num_hid_128_ld_1_ed_128__drop__0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g2fee6e6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_164922-g2fee6e6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g2fee6e6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc84d78305ff4645a56aeb211df3451d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669555133315347, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_164929-g2fee6e6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">lr_0.01_acti_NAdam_epochs_10_cell_GRU_dir_False_num_hid_128_ld_1_ed_128__drop__0.1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 36s (- 5m 31s) (1 10.00%) Trainloss: 0.7023 Char Accuracy: 78.2670 Word Accuracy: 4.6875\n",
      "0m 36s (- 5m 31s) (1 10.00%) Validationloss: 0.5401 Char Accuracy: 83.1310 Word Accuracy: 13.7939\n",
      "1m 12s (- 4m 51s) (2 20.00%) Trainloss: 0.2844 Char Accuracy: 91.9744 Word Accuracy: 14.0625\n",
      "1m 12s (- 4m 51s) (2 20.00%) Validationloss: 0.5267 Char Accuracy: 84.5648 Word Accuracy: 20.5078\n",
      "1m 50s (- 4m 18s) (3 30.00%) Trainloss: 0.3156 Char Accuracy: 91.1222 Word Accuracy: 18.7500\n",
      "1m 50s (- 4m 18s) (3 30.00%) Validationloss: 0.5077 Char Accuracy: 84.1553 Word Accuracy: 19.4336\n",
      "2m 27s (- 3m 41s) (4 40.00%) Trainloss: 0.2733 Char Accuracy: 93.0398 Word Accuracy: 25.0000\n",
      "2m 27s (- 3m 41s) (4 40.00%) Validationloss: 0.5072 Char Accuracy: 84.7235 Word Accuracy: 20.8008\n",
      "3m 4s (- 3m 4s) (5 50.00%) Trainloss: 0.2992 Char Accuracy: 91.9744 Word Accuracy: 17.1875\n",
      "3m 4s (- 3m 4s) (5 50.00%) Validationloss: 0.4929 Char Accuracy: 84.4682 Word Accuracy: 19.9951\n",
      "3m 40s (- 2m 27s) (6 60.00%) Trainloss: 0.5847 Char Accuracy: 80.7528 Word Accuracy: 15.6250\n",
      "3m 40s (- 2m 27s) (6 60.00%) Validationloss: 0.4788 Char Accuracy: 84.6147 Word Accuracy: 18.7988\n",
      "4m 17s (- 1m 50s) (7 70.00%) Trainloss: 1.8632 Char Accuracy: 60.8665 Word Accuracy: 0.0000\n",
      "4m 17s (- 1m 50s) (7 70.00%) Validationloss: 1.6658 Char Accuracy: 65.3620 Word Accuracy: 0.0000\n",
      "4m 53s (- 1m 13s) (8 80.00%) Trainloss: 1.8577 Char Accuracy: 61.6477 Word Accuracy: 0.0000\n",
      "4m 53s (- 1m 13s) (8 80.00%) Validationloss: 1.6344 Char Accuracy: 66.1244 Word Accuracy: 0.0000\n",
      "5m 30s (- 0m 36s) (9 90.00%) Trainloss: 1.2617 Char Accuracy: 66.1932 Word Accuracy: 0.0000\n",
      "5m 30s (- 0m 36s) (9 90.00%) Validationloss: 1.7007 Char Accuracy: 64.5885 Word Accuracy: 0.0000\n",
      "6m 6s (- 0m 0s) (10 100.00%) Trainloss: 1.2588 Char Accuracy: 66.2642 Word Accuracy: 0.0000\n",
      "6m 6s (- 0m 0s) (10 100.00%) Validationloss: 1.6757 Char Accuracy: 64.5896 Word Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.01_acti_NAdam_epochs_10_cell_GRU_dir_False_num_hid_128_ld_1_ed_128__drop__0.1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/g2fee6e6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_164929-g2fee6e6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uexdd2ev with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171200-uexdd2ev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">silvery-sweep-3</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.01_acti_Adam_epochs_10_cell_RNN_dir_False_num_hid_256_ld_2_ed_256__drop__0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:uexdd2ev) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7addd628d548f2959bcafc4e679728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-sweep-3</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171200-uexdd2ev/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:uexdd2ev). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171207-uexdd2ev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">lr_0.01_acti_Adam_epochs_10_cell_RNN_dir_False_num_hid_256_ld_2_ed_256__drop__0</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5478b6aa704f07b2177dcf30a34895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.077376…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.01_acti_Adam_epochs_10_cell_RNN_dir_False_num_hid_256_ld_2_ed_256__drop__0</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/uexdd2ev</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171207-uexdd2ev/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run uexdd2ev errored: RuntimeError('The expanded size of the tensor (68) must match the existing size (256) at non-singleton dimension 1.  Target sizes: [64, 68].  Tensor sizes: [64, 256]')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run uexdd2ev errored: RuntimeError('The expanded size of the tensor (68) must match the existing size (256) at non-singleton dimension 1.  Target sizes: [64, 68].  Tensor sizes: [64, 256]')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rrl22vz9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171251-rrl22vz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">distinctive-sweep-4</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_Adam_epochs_5_cell_GRU_dir_False_num_hid_512_ld_1_ed_512__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:rrl22vz9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d2135310b04e80be6225ee4644d0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-4</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171251-rrl22vz9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:rrl22vz9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171257-rrl22vz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">lr_0.001_acti_Adam_epochs_5_cell_GRU_dir_False_num_hid_512_ld_1_ed_512__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agcl/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 41s (- 2m 47s) (1 20.00%) Trainloss: 0.4803 Char Accuracy: 84.6591 Word Accuracy: 20.3125\n",
      "0m 41s (- 2m 47s) (1 20.00%) Validationloss: 0.4404 Char Accuracy: 85.8265 Word Accuracy: 23.9990\n",
      "1m 23s (- 2m 4s) (2 40.00%) Trainloss: 0.2033 Char Accuracy: 95.0994 Word Accuracy: 34.3750\n",
      "1m 23s (- 2m 4s) (2 40.00%) Validationloss: 0.4196 Char Accuracy: 87.1382 Word Accuracy: 30.5664\n",
      "2m 4s (- 1m 22s) (3 60.00%) Trainloss: 0.4155 Char Accuracy: 86.4347 Word Accuracy: 32.8125\n",
      "2m 4s (- 1m 22s) (3 60.00%) Validationloss: 0.3947 Char Accuracy: 87.4700 Word Accuracy: 30.9814\n",
      "2m 43s (- 0m 40s) (4 80.00%) Trainloss: 0.3855 Char Accuracy: 87.2159 Word Accuracy: 34.3750\n",
      "2m 43s (- 0m 40s) (4 80.00%) Validationloss: 0.3891 Char Accuracy: 87.9361 Word Accuracy: 33.1543\n",
      "3m 24s (- 0m 0s) (5 100.00%) Trainloss: 0.1682 Char Accuracy: 95.5966 Word Accuracy: 39.0625\n",
      "3m 24s (- 0m 0s) (5 100.00%) Validationloss: 0.3822 Char Accuracy: 88.3933 Word Accuracy: 34.4482\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.001_acti_Adam_epochs_5_cell_GRU_dir_False_num_hid_512_ld_1_ed_512__drop__0.2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/rrl22vz9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171257-rrl22vz9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zc09b7ak with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171651-zc09b7ak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">blooming-sweep-5</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_512_ld_2_ed_256__drop__0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zc09b7ak) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-5</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171651-zc09b7ak/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zc09b7ak). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_171657-zc09b7ak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_512_ld_2_ed_256__drop__0</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 24s (- 5m 37s) (1 20.00%) Trainloss: 1.1883 Char Accuracy: 69.1406 Word Accuracy: 0.0000\n",
      "1m 24s (- 5m 37s) (1 20.00%) Validationloss: 1.1173 Char Accuracy: 70.2881 Word Accuracy: 0.0000\n",
      "2m 53s (- 4m 20s) (2 40.00%) Trainloss: 1.3718 Char Accuracy: 64.4531 Word Accuracy: 0.0000\n",
      "2m 53s (- 4m 20s) (2 40.00%) Validationloss: 1.1763 Char Accuracy: 69.2960 Word Accuracy: 0.0000\n",
      "4m 31s (- 3m 1s) (3 60.00%) Trainloss: 1.2003 Char Accuracy: 67.7557 Word Accuracy: 0.0000\n",
      "4m 31s (- 3m 1s) (3 60.00%) Validationloss: 1.0332 Char Accuracy: 71.8828 Word Accuracy: 0.0000\n",
      "6m 10s (- 1m 32s) (4 80.00%) Trainloss: 1.2056 Char Accuracy: 67.3295 Word Accuracy: 0.0000\n",
      "6m 10s (- 1m 32s) (4 80.00%) Validationloss: 1.0544 Char Accuracy: 71.8328 Word Accuracy: 0.0000\n",
      "7m 47s (- 0m 0s) (5 100.00%) Trainloss: 1.0985 Char Accuracy: 71.2003 Word Accuracy: 0.0000\n",
      "7m 47s (- 0m 0s) (5 100.00%) Validationloss: 1.0032 Char Accuracy: 72.9725 Word Accuracy: 0.0732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9236ce5c6af49c2a69804525c87dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_512_ld_2_ed_256__drop__0</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/zc09b7ak</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_171657-zc09b7ak/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dobgu6eg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174101-dobgu6eg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">astral-sweep-6</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_Adam_epochs_5_cell_LSTM_dir_False_num_hid_256_ld_1_ed_256__drop__0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dobgu6eg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-6</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174101-dobgu6eg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dobgu6eg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174108-dobgu6eg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">lr_0.001_acti_Adam_epochs_5_cell_LSTM_dir_False_num_hid_256_ld_1_ed_256__drop__0</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 19s (- 1m 19s) (1 20.00%) Trainloss: 0.8375 Char Accuracy: 76.7756 Word Accuracy: 3.1250\n",
      "0m 19s (- 1m 19s) (1 20.00%) Validationloss: 0.7164 Char Accuracy: 80.1225 Word Accuracy: 5.6641\n",
      "0m 39s (- 0m 59s) (2 40.00%) Trainloss: 0.6082 Char Accuracy: 81.6761 Word Accuracy: 14.0625\n",
      "0m 39s (- 0m 59s) (2 40.00%) Validationloss: 0.4958 Char Accuracy: 84.5992 Word Accuracy: 18.1396\n",
      "0m 59s (- 0m 39s) (3 60.00%) Trainloss: 0.2549 Char Accuracy: 92.6136 Word Accuracy: 19.5312\n",
      "0m 59s (- 0m 39s) (3 60.00%) Validationloss: 0.4550 Char Accuracy: 85.8476 Word Accuracy: 23.5596\n",
      "1m 18s (- 0m 19s) (4 80.00%) Trainloss: 0.2241 Char Accuracy: 93.8565 Word Accuracy: 28.1250\n",
      "1m 18s (- 0m 19s) (4 80.00%) Validationloss: 0.4120 Char Accuracy: 87.0017 Word Accuracy: 28.6865\n",
      "1m 38s (- 0m 0s) (5 100.00%) Trainloss: 0.1872 Char Accuracy: 94.7443 Word Accuracy: 33.5938\n",
      "1m 38s (- 0m 0s) (5 100.00%) Validationloss: 0.4191 Char Accuracy: 87.2670 Word Accuracy: 30.7617\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d83143ca3947c0b7970f740018c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.001_acti_Adam_epochs_5_cell_LSTM_dir_False_num_hid_256_ld_1_ed_256__drop__0</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/dobgu6eg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174108-dobgu6eg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67s74323 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174321-67s74323</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">genial-sweep-7</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_128_ld_1_ed_128__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:67s74323) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fbb5b25d2b420c872cab94ff412349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-7</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174321-67s74323/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:67s74323). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174328-67s74323</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_128_ld_1_ed_128__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 24s (- 1m 36s) (1 20.00%) Trainloss: 0.8531 Char Accuracy: 75.0710 Word Accuracy: 0.0000\n",
      "0m 24s (- 1m 36s) (1 20.00%) Validationloss: 1.0817 Char Accuracy: 71.1559 Word Accuracy: 0.1953\n",
      "0m 49s (- 1m 14s) (2 40.00%) Trainloss: 0.5690 Char Accuracy: 83.4872 Word Accuracy: 4.6875\n",
      "0m 49s (- 1m 14s) (2 40.00%) Validationloss: 0.7031 Char Accuracy: 78.6466 Word Accuracy: 4.4678\n",
      "1m 13s (- 0m 49s) (3 60.00%) Trainloss: 0.6780 Char Accuracy: 78.1605 Word Accuracy: 6.2500\n",
      "1m 13s (- 0m 49s) (3 60.00%) Validationloss: 0.5593 Char Accuracy: 82.1367 Word Accuracy: 13.5986\n",
      "1m 39s (- 0m 24s) (4 80.00%) Trainloss: 0.6271 Char Accuracy: 80.2912 Word Accuracy: 14.0625\n",
      "1m 39s (- 0m 24s) (4 80.00%) Validationloss: 0.5190 Char Accuracy: 83.5527 Word Accuracy: 18.9209\n",
      "2m 3s (- 0m 0s) (5 100.00%) Trainloss: 0.3127 Char Accuracy: 91.5838 Word Accuracy: 17.9688\n",
      "2m 3s (- 0m 0s) (5 100.00%) Validationloss: 0.5004 Char Accuracy: 84.7801 Word Accuracy: 22.5586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.01_acti_NAdam_epochs_5_cell_LSTM_dir_True_num_hid_128_ld_1_ed_128__drop__0.2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/67s74323</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174328-67s74323/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f9ccjxnx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174601-f9ccjxnx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">eager-sweep-8</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_NAdam_epochs_10_cell_RNN_dir_True_num_hid_512_ld_1_ed_128__drop__0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:f9ccjxnx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7911e06e69c445e993234661fba4a953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-8</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174601-f9ccjxnx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:f9ccjxnx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174608-f9ccjxnx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">lr_0.001_acti_NAdam_epochs_10_cell_RNN_dir_True_num_hid_512_ld_1_ed_128__drop__0.1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5f6f32637f4201be7d9e4a44ebe079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.018 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.652032…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.001_acti_NAdam_epochs_10_cell_RNN_dir_True_num_hid_512_ld_1_ed_128__drop__0.1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/f9ccjxnx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174608-f9ccjxnx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run f9ccjxnx errored: RuntimeError('The expanded size of the tensor (68) must match the existing size (1024) at non-singleton dimension 1.  Target sizes: [64, 68].  Tensor sizes: [64, 1024]')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run f9ccjxnx errored: RuntimeError('The expanded size of the tensor (68) must match the existing size (1024) at non-singleton dimension 1.  Target sizes: [64, 68].  Tensor sizes: [64, 1024]')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qyxhyau6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174633-qyxhyau6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">swept-sweep-9</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.01_acti_Adam_epochs_10_cell_GRU_dir_True_num_hid_128_ld_1_ed_128__drop__0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qyxhyau6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-9</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174633-qyxhyau6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qyxhyau6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_174639-qyxhyau6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">lr_0.01_acti_Adam_epochs_10_cell_GRU_dir_True_num_hid_128_ld_1_ed_128__drop__0.1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 25s (- 3m 51s) (1 10.00%) Trainloss: 0.5825 Char Accuracy: 83.5938 Word Accuracy: 3.9062\n",
      "0m 25s (- 3m 51s) (1 10.00%) Validationloss: 0.7345 Char Accuracy: 77.7433 Word Accuracy: 5.2734\n",
      "0m 56s (- 3m 46s) (2 20.00%) Trainloss: 0.7664 Char Accuracy: 76.2074 Word Accuracy: 7.8125\n",
      "0m 56s (- 3m 46s) (2 20.00%) Validationloss: 0.6314 Char Accuracy: 80.6041 Word Accuracy: 10.3027\n",
      "1m 27s (- 3m 23s) (3 30.00%) Trainloss: 0.4200 Char Accuracy: 87.4290 Word Accuracy: 9.3750\n",
      "1m 27s (- 3m 23s) (3 30.00%) Validationloss: 0.5698 Char Accuracy: 81.7105 Word Accuracy: 12.8418\n",
      "1m 58s (- 2m 57s) (4 40.00%) Trainloss: 0.6632 Char Accuracy: 78.2670 Word Accuracy: 11.7188\n",
      "1m 58s (- 2m 57s) (4 40.00%) Validationloss: 0.5452 Char Accuracy: 82.4518 Word Accuracy: 13.7451\n",
      "2m 29s (- 2m 29s) (5 50.00%) Trainloss: 0.3469 Char Accuracy: 90.1989 Word Accuracy: 14.8438\n",
      "2m 29s (- 2m 29s) (5 50.00%) Validationloss: 0.5493 Char Accuracy: 83.0211 Word Accuracy: 17.3828\n",
      "3m 0s (- 2m 0s) (6 60.00%) Trainloss: 0.6588 Char Accuracy: 79.0838 Word Accuracy: 11.7188\n",
      "3m 0s (- 2m 0s) (6 60.00%) Validationloss: 0.5339 Char Accuracy: 83.0333 Word Accuracy: 16.9678\n",
      "3m 31s (- 1m 30s) (7 70.00%) Trainloss: 0.6070 Char Accuracy: 79.8651 Word Accuracy: 10.1562\n",
      "3m 31s (- 1m 30s) (7 70.00%) Validationloss: 0.5312 Char Accuracy: 82.8869 Word Accuracy: 15.9424\n",
      "4m 2s (- 1m 0s) (8 80.00%) Trainloss: 0.3540 Char Accuracy: 89.8082 Word Accuracy: 12.5000\n",
      "4m 2s (- 1m 0s) (8 80.00%) Validationloss: 0.5236 Char Accuracy: 83.3108 Word Accuracy: 16.7969\n",
      "4m 33s (- 0m 30s) (9 90.00%) Trainloss: 0.3336 Char Accuracy: 90.1634 Word Accuracy: 14.8438\n",
      "4m 33s (- 0m 30s) (9 90.00%) Validationloss: 0.5794 Char Accuracy: 82.5084 Word Accuracy: 17.5049\n",
      "5m 3s (- 0m 0s) (10 100.00%) Trainloss: 0.5657 Char Accuracy: 81.3210 Word Accuracy: 14.8438\n",
      "5m 3s (- 0m 0s) (10 100.00%) Validationloss: 0.5191 Char Accuracy: 83.4162 Word Accuracy: 17.7002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.01_acti_Adam_epochs_10_cell_GRU_dir_True_num_hid_128_ld_1_ed_128__drop__0.1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/qyxhyau6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_174639-qyxhyau6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ki5rqyeo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/agcl/Downloads/CS6910_ASSIGNMENT_3-ATTENTION-model2.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_180759-ki5rqyeo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo' target=\"_blank\">spring-sweep-10</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_Adam_epochs_5_cell_LSTM_dir_True_num_hid_512_ld_1_ed_512__drop__0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ki5rqyeo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-10</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_180759-ki5rqyeo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ki5rqyeo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_180806-ki5rqyeo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo' target=\"_blank\">lr_0.001_acti_Adam_epochs_5_cell_LSTM_dir_True_num_hid_512_ld_1_ed_512__drop__0</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/t4jo8lzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/ki5rqyeo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 19s (- 5m 17s) (1 20.00%) Trainloss: 0.8626 Char Accuracy: 75.7812 Word Accuracy: 0.0000\n",
      "1m 19s (- 5m 17s) (1 20.00%) Validationloss: 1.0378 Char Accuracy: 71.4478 Word Accuracy: 0.0244\n",
      "2m 38s (- 3m 57s) (2 40.00%) Trainloss: 0.7417 Char Accuracy: 78.4091 Word Accuracy: 10.9375\n",
      "2m 38s (- 3m 57s) (2 40.00%) Validationloss: 0.5845 Char Accuracy: 82.0290 Word Accuracy: 12.4512\n",
      "3m 58s (- 2m 38s) (3 60.00%) Trainloss: 0.5755 Char Accuracy: 81.1790 Word Accuracy: 18.7500\n",
      "3m 58s (- 2m 38s) (3 60.00%) Validationloss: 0.4768 Char Accuracy: 84.5803 Word Accuracy: 20.0928\n",
      "5m 20s (- 1m 20s) (4 80.00%) Trainloss: 0.4705 Char Accuracy: 85.0142 Word Accuracy: 29.6875\n",
      "5m 20s (- 1m 20s) (4 80.00%) Validationloss: 0.4437 Char Accuracy: 86.1217 Word Accuracy: 26.9043\n",
      "7m 2s (- 0m 0s) (5 100.00%) Trainloss: 0.2136 Char Accuracy: 93.7500 Word Accuracy: 29.6875\n",
      "7m 2s (- 0m 0s) (5 100.00%) Validationloss: 0.4329 Char Accuracy: 86.3803 Word Accuracy: 27.2705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e131cf70af334897810a21b37c0c5e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.027 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.077362…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "# Sweep configuration for wandb\n",
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {\n",
    "        'name': 'valid_word_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'optimizer': {\n",
    "            'values': ['Adam', 'NAdam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001, 0.005, 0.01]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [5, 10, 20]\n",
    "        },\n",
    "        'hidden_dim': {\n",
    "            'values': [128,256,512]\n",
    "        },\n",
    "        'layer_dim': {\n",
    "            'values': [1,2]\n",
    "        },\n",
    "        'embed_dim': {\n",
    "            'values': [128,256,512]\n",
    "        },\n",
    "        'drop_out': {\n",
    "            'values': [0, 0.1, 0.2]\n",
    "        },\n",
    "        'cell': {\n",
    "            'values': ['RNN', 'LSTM', 'GRU']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64,128]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0.0001]\n",
    "        },\n",
    "        'bi_dir': {\n",
    "            'values': [True, False]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='CS6910-ASSIGNMENT_3')\n",
    "wandb.agent(sweep_id, function=wandb_run, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc3ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
