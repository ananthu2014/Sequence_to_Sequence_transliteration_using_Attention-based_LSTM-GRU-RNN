{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabfad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import random\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3654d4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff65f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mananthu2014\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9caa5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = '/home/agcl/Downloads/CS6910_ASSIGNMENT_3-without attention-sweeps.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0da7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function to load the data'''\n",
    "def load_data(path,language_names):\n",
    "    df=pd.read_csv(path,header=None)\n",
    "    df.columns=language_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75791f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shastragaar</td>\n",
       "      <td>शस्त्रागार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>toned</td>\n",
       "      <td>टोंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>mutanaazaa</td>\n",
       "      <td>मुतनाज़ा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>asahmaton</td>\n",
       "      <td>असहमतों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>sulgaayin</td>\n",
       "      <td>सुलगायीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>anchuthengu</td>\n",
       "      <td>अंचुतेंगु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           English transliteration_in_hindi\n",
       "0      shastragaar               शस्त्रागार\n",
       "1          bindhya                 बिन्द्या\n",
       "2        kirankant                 किरणकांत\n",
       "3      yagyopaveet                यज्ञोपवीत\n",
       "4          ratania                  रटानिया\n",
       "...            ...                      ...\n",
       "51195        toned                     टोंड\n",
       "51196   mutanaazaa                 मुतनाज़ा\n",
       "51197    asahmaton                  असहमतों\n",
       "51198    sulgaayin                 सुलगायीं\n",
       "51199  anchuthengu                अंचुतेंगु\n",
       "\n",
       "[51200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Here,basically,the input is given to the encoder in English language and is transliterated to Hindi\n",
    "by the decoder'''\n",
    "path_train=\"/home/agcl/Downloads/hin_train.csv\"\n",
    "language_names = ['English','transliteration_in_hindi']\n",
    "df_train=load_data(path_train,language_names)\n",
    "print(df_train.shape)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b822674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 2)\n",
      "(4096, 2)\n"
     ]
    }
   ],
   "source": [
    "#path_test=\"C:/Users/anant/Downloads/hin_test.csv\"\n",
    "path_test=\"/home/agcl/Downloads/hin_test.csv\"\n",
    "#path_validation=\"C:/Users/anant/Downloads/hin_valid.csv\"\n",
    "path_validation=\"/home/agcl/Downloads/hin_valid.csv\"\n",
    "df_validation=load_data(path_validation,language_names)\n",
    "print(df_validation.shape)\n",
    "df_test=load_data(path_test,language_names)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f13c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for acquiring all the characters of the given data'''\n",
    "def split_words(x):\n",
    "    x=np.array(x)\n",
    "    alpha=['_','\\t','\\n',' '] #pad token, start of word, end of word and unknown tokens\n",
    "    b=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        a=list(x[i])\n",
    "        for j in range(len(a)):\n",
    "            if a[j] not in b:\n",
    "                b.append(a[j])\n",
    "    b=sorted(b)\n",
    "    alpha=alpha+b\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d5c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''All the english characters are stored into the list english_vocab and all the hindi characters are\n",
    "stored into the list hindi_vocab'''\n",
    "english_vocab=split_words(df_train['English'])\n",
    "hindi_vocab=split_words(df_train['transliteration_in_hindi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766389b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "68\n",
      "['_', '\\t', '\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['_', '\\t', '\\n', ' ', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n"
     ]
    }
   ],
   "source": [
    "print(len(english_vocab))\n",
    "print(len(hindi_vocab))\n",
    "print(english_vocab)\n",
    "print(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "209154f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions to create the vocabulary dictionaries with their indices'''\n",
    "def int_to_char(vocab):\n",
    "    int2char={} #padding token, start of word, end of word token and unknown token\n",
    "    for i in range(len(vocab)):\n",
    "        int2char[i]=vocab[i][0]\n",
    "    return int2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49dc0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    }
   ],
   "source": [
    "int2char_eng=int_to_char(english_vocab)\n",
    "print(int2char_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a0b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_int(int2char):\n",
    "    char2int={ch:ii for ii,ch in int2char.items()}\n",
    "    return char2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6336f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "char2int_eng=char_to_int(int2char_eng)\n",
    "print(char2int_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5edad018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'ँ', 5: 'ं', 6: 'ः', 7: 'अ', 8: 'आ', 9: 'इ', 10: 'ई', 11: 'उ', 12: 'ऊ', 13: 'ऋ', 14: 'ए', 15: 'ऐ', 16: 'ऑ', 17: 'ओ', 18: 'औ', 19: 'क', 20: 'ख', 21: 'ग', 22: 'घ', 23: 'ङ', 24: 'च', 25: 'छ', 26: 'ज', 27: 'झ', 28: 'ञ', 29: 'ट', 30: 'ठ', 31: 'ड', 32: 'ढ', 33: 'ण', 34: 'त', 35: 'थ', 36: 'द', 37: 'ध', 38: 'न', 39: 'प', 40: 'फ', 41: 'ब', 42: 'भ', 43: 'म', 44: 'य', 45: 'र', 46: 'ल', 47: 'ळ', 48: 'व', 49: 'श', 50: 'ष', 51: 'स', 52: 'ह', 53: '़', 54: 'ऽ', 55: 'ा', 56: 'ि', 57: 'ी', 58: 'ु', 59: 'ू', 60: 'ृ', 61: 'ॅ', 62: 'े', 63: 'ै', 64: 'ॉ', 65: 'ो', 66: 'ौ', 67: '्'}\n"
     ]
    }
   ],
   "source": [
    "int2char_hin=int_to_char(hindi_vocab)\n",
    "print(int2char_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c7a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'अ': 7, 'आ': 8, 'इ': 9, 'ई': 10, 'उ': 11, 'ऊ': 12, 'ऋ': 13, 'ए': 14, 'ऐ': 15, 'ऑ': 16, 'ओ': 17, 'औ': 18, 'क': 19, 'ख': 20, 'ग': 21, 'घ': 22, 'ङ': 23, 'च': 24, 'छ': 25, 'ज': 26, 'झ': 27, 'ञ': 28, 'ट': 29, 'ठ': 30, 'ड': 31, 'ढ': 32, 'ण': 33, 'त': 34, 'थ': 35, 'द': 36, 'ध': 37, 'न': 38, 'प': 39, 'फ': 40, 'ब': 41, 'भ': 42, 'म': 43, 'य': 44, 'र': 45, 'ल': 46, 'ळ': 47, 'व': 48, 'श': 49, 'ष': 50, 'स': 51, 'ह': 52, '़': 53, 'ऽ': 54, 'ा': 55, 'ि': 56, 'ी': 57, 'ु': 58, 'ू': 59, 'ृ': 60, 'ॅ': 61, 'े': 62, 'ै': 63, 'ॉ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n"
     ]
    }
   ],
   "source": [
    "char2int_hin=char_to_int(int2char_hin)\n",
    "print(char2int_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c0f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finding the maximum sequence length'''\n",
    "length_eng=[len(i) for i in df_train['English']]\n",
    "length_hin=[len(i) for i in df_train['transliteration_in_hindi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "569c1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sequence length of English words is 26\n",
      "The maximum sequence length of transliterated words is 22\n"
     ]
    }
   ],
   "source": [
    "length_eng_max=max(length_eng)+2 #we have to account for the start and end token\n",
    "print(f'The maximum sequence length of English words is {length_eng_max}')\n",
    "length_hin_max=max(length_hin)+2\n",
    "print(f'The maximum sequence length of transliterated words is {length_hin_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00064a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "num_english_tokens=len(english_vocab)\n",
    "print(num_english_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e3fabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "num_hindi_tokens=len(hindi_vocab)\n",
    "print(num_hindi_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc02bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shastragaar</td>\n",
       "      <td>शस्त्रागार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>toned</td>\n",
       "      <td>टोंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>mutanaazaa</td>\n",
       "      <td>मुतनाज़ा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>asahmaton</td>\n",
       "      <td>असहमतों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>sulgaayin</td>\n",
       "      <td>सुलगायीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>anchuthengu</td>\n",
       "      <td>अंचुतेंगु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           English transliteration_in_hindi\n",
       "0      shastragaar               शस्त्रागार\n",
       "1          bindhya                 बिन्द्या\n",
       "2        kirankant                 किरणकांत\n",
       "3      yagyopaveet                यज्ञोपवीत\n",
       "4          ratania                  रटानिया\n",
       "...            ...                      ...\n",
       "51195        toned                     टोंड\n",
       "51196   mutanaazaa                 मुतनाज़ा\n",
       "51197    asahmaton                  असहमतों\n",
       "51198    sulgaayin                 सुलगायीं\n",
       "51199  anchuthengu                अंचुतेंगु\n",
       "\n",
       "[51200 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29cd6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(length_eng_max)\n",
    "print(length_hin_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56f79e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '_', 1: '\\t', 2: '\\n', 3: ' ', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The position of padding is zero itself, so we can create tensors using torch.zeros and proceed'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int2char_eng)\n",
    "'''The position of padding is zero itself, so we can create tensors using torch.zeros and proceed'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dfa059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df['English'] = df['English'].str.lower()\n",
    "    df['transliteration_in_hindi'] = df['transliteration_in_hindi'].str.lower()\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    '''Adding start and end of word tokens'''\n",
    "    y_og = df['transliteration_in_hindi'].values\n",
    "    x_og = df['English'].values\n",
    "    x = '\\t'+x_og+'\\n'\n",
    "    y = '\\t'+y_og+'\\n'\n",
    "    y_do=y_og+'\\n'\n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    \n",
    "    enc_input_data=torch.zeros(len(x),length_eng_max)\n",
    "    dec_input_data=torch.zeros(len(y),length_hin_max)\n",
    "    dec_output_data=torch.zeros(len(y),length_hin_max)\n",
    "    for i, (xx,yy) in enumerate(zip(x,y)):\n",
    "        for j,char in enumerate(xx):\n",
    "            enc_input_data[i,j]=char2int_eng[char]\n",
    "        #pad character is zero so no need of assigning it again\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_input_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char]\n",
    "    \n",
    "    for i, (xx,yy) in enumerate(zip(x,y_do)):\n",
    "        for j,char in enumerate(yy):\n",
    "            if char in hindi_vocab:\n",
    "                dec_output_data[i,j]=char2int_hin[char]\n",
    "            else:\n",
    "                dec_input_data[i,j]=char2int_hin[unknown_char]\n",
    "                \n",
    "    return enc_input_data,dec_input_data,dec_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e201b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,english_vocab=english_vocab,hindi_vocab=hindi_vocab,\n",
    "                 length_eng_max=length_eng_max,length_hin_max=length_hin_max,char2int_eng=char2int_eng\n",
    "                 ,char2int_hin=char2int_hin):\n",
    "    \n",
    "    \n",
    "    '''removing words of length more than max length'''\n",
    "    df = df[df['English'].apply(len) <= length_eng_max-2]\n",
    "    df = df[df['transliteration_in_hindi'].apply(len) <= length_hin_max-2]\n",
    "    '''Adding start and end of word tokens'''\n",
    "    y = df['transliteration_in_hindi'].values\n",
    "    x= df['English'].values\n",
    "    x = '\\t'+x+'\\n'\n",
    "    y = '\\t'+y+'\\n'\n",
    "    \n",
    "    unknown=3\n",
    "    pad=0\n",
    "    pad_char='_'\n",
    "    unknown_char=' '\n",
    "    start=1\n",
    "    end=2\n",
    "    \n",
    "    encoder_input_data = np.zeros(\n",
    "    (len(df['English']), length_eng_max, num_english_tokens), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "    decoder_output_data = np.zeros(\n",
    "    (len(df['transliteration_in_hindi']), length_hin_max, num_hindi_tokens), dtype=\"float32\")\n",
    "    pad_char='_'\n",
    "    for i , (input_text,target_text) in enumerate(zip(x,y)):\n",
    "        for t,char in enumerate(input_text):\n",
    "            encoder_input_data[i,t,char2int_eng[char]]=1\n",
    "        encoder_input_data[i,t+1:,char2int_eng[pad_char]]=1\n",
    "    \n",
    "        for t,char in enumerate(target_text):\n",
    "            if char in hindi_vocab:\n",
    "                decoder_input_data[i,t,char2int_hin[char]]=1\n",
    "            else:\n",
    "                decoder_input_data[i,t,char2int_hin[unknown_char]]=1\n",
    "        decoder_input_data[i,t+1:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "        '''decoder target data is one step ahead of decoder input data by one timestep\n",
    "        and doesnot includes start token'''\n",
    "        for t,char in enumerate(target_text):\n",
    "            if t>0:\n",
    "                if char in hindi_vocab:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[char]]=1\n",
    "                else:\n",
    "                    decoder_output_data[i,t-1,char2int_hin[unknown_char]]=1\n",
    "                \n",
    "        decoder_output_data[i,t:,char2int_hin[pad_char]]=1\n",
    "    \n",
    "    return torch.tensor(encoder_input_data),torch.tensor(decoder_input_data),torch.tensor(decoder_output_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e5dcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data,dec_input_data,dec_output_data=process_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "407cc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data,decoder_input_data,decoder_output_data=one_hot_encoding(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14b89fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26])\n",
      "torch.Size([51200, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data.shape)\n",
    "print(dec_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9938947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200, 26, 30])\n",
      "torch.Size([51200, 22, 68])\n",
      "torch.Size([51200, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "595cf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., 49., 51., 67., 34., 67., 45., 55., 21., 55., 45.,  2.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "print(dec_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f82c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49., 51., 67., 34., 67., 45., 55., 21., 55., 45.,  2.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "print(dec_output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee105331",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data_test,dec_input_data_test,dec_output_data_test=process_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7c2e103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4095, 26])\n",
      "torch.Size([4095, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data_test.shape)\n",
    "print(dec_input_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7e8f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data_val,dec_input_data_val,dec_output_data_val=process_data(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddd75195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 26])\n",
      "torch.Size([4096, 22])\n"
     ]
    }
   ],
   "source": [
    "print(enc_input_data_val.shape)\n",
    "print(dec_input_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50840ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_test,decoder_input_data_test,decoder_output_data_test=one_hot_encoding(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13049fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4095, 26, 30])\n",
      "torch.Size([4095, 22, 68])\n",
      "torch.Size([4095, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_test.shape)\n",
    "print(decoder_input_data_test.shape)\n",
    "print(decoder_output_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d064dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data_val,decoder_input_data_val,decoder_output_data_val=one_hot_encoding(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8130566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 26, 30])\n",
      "torch.Size([4096, 22, 68])\n",
      "torch.Size([4096, 22, 68])\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)\n",
    "print(decoder_output_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31b80fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 49, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 41, 56,  ...,  0,  0,  0],\n",
      "        [ 1, 19, 56,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 1,  7, 51,  ...,  0,  0,  0],\n",
      "        [ 1, 51, 58,  ...,  0,  0,  0],\n",
      "        [ 1,  7,  5,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(decoder_input_data,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8987d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., 49., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 41., 56.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 19., 56.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 1.,  7., 51.,  ...,  0.,  0.,  0.],\n",
      "        [ 1., 51., 58.,  ...,  0.,  0.,  0.],\n",
      "        [ 1.,  7.,  5.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(dec_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09800fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49, 51, 67,  ...,  0,  0,  0],\n",
      "        [41, 56, 38,  ...,  0,  0,  0],\n",
      "        [19, 56, 45,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 7, 51, 52,  ...,  0,  0,  0],\n",
      "        [51, 58, 46,  ...,  0,  0,  0],\n",
      "        [ 7,  5, 24,  ...,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(decoder_output_data,dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e12e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49., 51., 67.,  ...,  0.,  0.,  0.],\n",
      "        [41., 56., 38.,  ...,  0.,  0.,  0.],\n",
      "        [19., 56., 45.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 7., 51., 52.,  ...,  0.,  0.,  0.],\n",
      "        [51., 58., 46.,  ...,  0.,  0.,  0.],\n",
      "        [ 7.,  5., 24.,  ...,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print(dec_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "549cb4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['transliteration_in_hindi']='\\t'+df_train['transliteration_in_hindi']+'\\n'\n",
    "df_train['English']='\\t'+df_train['English']+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30e0f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['English_seq'] = df_train['English'].apply(lambda x: [char2int_eng[char] for char in x])\n",
    "df_train['transliteration_seq'] = df_train['transliteration_in_hindi'].apply(lambda x: [char2int_hin[char] for char in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aafc2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29}\n"
     ]
    }
   ],
   "source": [
    "print(char2int_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19777c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, '\\t': 1, '\\n': 2, ' ': 3, 'ँ': 4, 'ं': 5, 'ः': 6, 'अ': 7, 'आ': 8, 'इ': 9, 'ई': 10, 'उ': 11, 'ऊ': 12, 'ऋ': 13, 'ए': 14, 'ऐ': 15, 'ऑ': 16, 'ओ': 17, 'औ': 18, 'क': 19, 'ख': 20, 'ग': 21, 'घ': 22, 'ङ': 23, 'च': 24, 'छ': 25, 'ज': 26, 'झ': 27, 'ञ': 28, 'ट': 29, 'ठ': 30, 'ड': 31, 'ढ': 32, 'ण': 33, 'त': 34, 'थ': 35, 'द': 36, 'ध': 37, 'न': 38, 'प': 39, 'फ': 40, 'ब': 41, 'भ': 42, 'म': 43, 'य': 44, 'र': 45, 'ल': 46, 'ळ': 47, 'व': 48, 'श': 49, 'ष': 50, 'स': 51, 'ह': 52, '़': 53, 'ऽ': 54, 'ा': 55, 'ि': 56, 'ी': 57, 'ु': 58, 'ू': 59, 'ृ': 60, 'ॅ': 61, 'े': 62, 'ै': 63, 'ॉ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n"
     ]
    }
   ],
   "source": [
    "print(char2int_hin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e861d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>transliteration_in_hindi</th>\n",
       "      <th>English_seq</th>\n",
       "      <th>transliteration_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\tshastragaar\\n</td>\n",
       "      <td>\\tशस्त्रागार\\n</td>\n",
       "      <td>[1, 22, 11, 4, 22, 23, 21, 4, 10, 4, 4, 21, 2]</td>\n",
       "      <td>[1, 49, 51, 67, 34, 67, 45, 55, 21, 55, 45, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\tbindhya\\n</td>\n",
       "      <td>\\tबिन्द्या\\n</td>\n",
       "      <td>[1, 5, 12, 17, 7, 11, 28, 4, 2]</td>\n",
       "      <td>[1, 41, 56, 38, 67, 36, 67, 44, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tkirankant\\n</td>\n",
       "      <td>\\tकिरणकांत\\n</td>\n",
       "      <td>[1, 14, 12, 21, 4, 17, 14, 4, 17, 23, 2]</td>\n",
       "      <td>[1, 19, 56, 45, 33, 19, 55, 5, 34, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tyagyopaveet\\n</td>\n",
       "      <td>\\tयज्ञोपवीत\\n</td>\n",
       "      <td>[1, 28, 4, 10, 28, 18, 19, 4, 25, 8, 8, 23, 2]</td>\n",
       "      <td>[1, 44, 26, 67, 28, 65, 39, 48, 57, 34, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tratania\\n</td>\n",
       "      <td>\\tरटानिया\\n</td>\n",
       "      <td>[1, 21, 4, 23, 4, 17, 12, 4, 2]</td>\n",
       "      <td>[1, 45, 29, 55, 38, 56, 44, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>\\ttoned\\n</td>\n",
       "      <td>\\tटोंड\\n</td>\n",
       "      <td>[1, 23, 18, 17, 8, 7, 2]</td>\n",
       "      <td>[1, 29, 65, 5, 31, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>\\tmutanaazaa\\n</td>\n",
       "      <td>\\tमुतनाज़ा\\n</td>\n",
       "      <td>[1, 16, 24, 23, 4, 17, 4, 4, 29, 4, 4, 2]</td>\n",
       "      <td>[1, 43, 58, 34, 38, 55, 26, 53, 55, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>\\tasahmaton\\n</td>\n",
       "      <td>\\tअसहमतों\\n</td>\n",
       "      <td>[1, 4, 22, 4, 11, 16, 4, 23, 18, 17, 2]</td>\n",
       "      <td>[1, 7, 51, 52, 43, 34, 65, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>\\tsulgaayin\\n</td>\n",
       "      <td>\\tसुलगायीं\\n</td>\n",
       "      <td>[1, 22, 24, 15, 10, 4, 4, 28, 12, 17, 2]</td>\n",
       "      <td>[1, 51, 58, 46, 21, 55, 44, 57, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>\\tanchuthengu\\n</td>\n",
       "      <td>\\tअंचुतेंगु\\n</td>\n",
       "      <td>[1, 4, 17, 6, 11, 24, 23, 11, 8, 17, 10, 24, 2]</td>\n",
       "      <td>[1, 7, 5, 24, 58, 34, 62, 5, 21, 58, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               English transliteration_in_hindi  \\\n",
       "0      \\tshastragaar\\n           \\tशस्त्रागार\\n   \n",
       "1          \\tbindhya\\n             \\tबिन्द्या\\n   \n",
       "2        \\tkirankant\\n             \\tकिरणकांत\\n   \n",
       "3      \\tyagyopaveet\\n            \\tयज्ञोपवीत\\n   \n",
       "4          \\tratania\\n              \\tरटानिया\\n   \n",
       "...                ...                      ...   \n",
       "51195        \\ttoned\\n                 \\tटोंड\\n   \n",
       "51196   \\tmutanaazaa\\n             \\tमुतनाज़ा\\n   \n",
       "51197    \\tasahmaton\\n              \\tअसहमतों\\n   \n",
       "51198    \\tsulgaayin\\n             \\tसुलगायीं\\n   \n",
       "51199  \\tanchuthengu\\n            \\tअंचुतेंगु\\n   \n",
       "\n",
       "                                           English_seq  \\\n",
       "0       [1, 22, 11, 4, 22, 23, 21, 4, 10, 4, 4, 21, 2]   \n",
       "1                      [1, 5, 12, 17, 7, 11, 28, 4, 2]   \n",
       "2             [1, 14, 12, 21, 4, 17, 14, 4, 17, 23, 2]   \n",
       "3       [1, 28, 4, 10, 28, 18, 19, 4, 25, 8, 8, 23, 2]   \n",
       "4                      [1, 21, 4, 23, 4, 17, 12, 4, 2]   \n",
       "...                                                ...   \n",
       "51195                         [1, 23, 18, 17, 8, 7, 2]   \n",
       "51196        [1, 16, 24, 23, 4, 17, 4, 4, 29, 4, 4, 2]   \n",
       "51197          [1, 4, 22, 4, 11, 16, 4, 23, 18, 17, 2]   \n",
       "51198         [1, 22, 24, 15, 10, 4, 4, 28, 12, 17, 2]   \n",
       "51199  [1, 4, 17, 6, 11, 24, 23, 11, 8, 17, 10, 24, 2]   \n",
       "\n",
       "                                  transliteration_seq  \n",
       "0      [1, 49, 51, 67, 34, 67, 45, 55, 21, 55, 45, 2]  \n",
       "1              [1, 41, 56, 38, 67, 36, 67, 44, 55, 2]  \n",
       "2               [1, 19, 56, 45, 33, 19, 55, 5, 34, 2]  \n",
       "3          [1, 44, 26, 67, 28, 65, 39, 48, 57, 34, 2]  \n",
       "4                  [1, 45, 29, 55, 38, 56, 44, 55, 2]  \n",
       "...                                               ...  \n",
       "51195                           [1, 29, 65, 5, 31, 2]  \n",
       "51196          [1, 43, 58, 34, 38, 55, 26, 53, 55, 2]  \n",
       "51197                [1, 7, 51, 52, 43, 34, 65, 5, 2]  \n",
       "51198           [1, 51, 58, 46, 21, 55, 44, 57, 5, 2]  \n",
       "51199         [1, 7, 5, 24, 58, 34, 62, 5, 21, 58, 2]  \n",
       "\n",
       "[51200 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22627fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input_data=enc_input_data.long()\n",
    "dec_input_data=dec_input_data.long()\n",
    "enc_input_data_test=enc_input_data_test.long()\n",
    "dec_input_data_test=dec_input_data_test.long()\n",
    "enc_input_data_val=enc_input_data_val.long()\n",
    "dec_input_data_val=dec_input_data_val.long()\n",
    "encoder_input_data=encoder_input_data.long()\n",
    "decoder_input_data=decoder_input_data.long()\n",
    "decoder_output_data=decoder_output_data.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d756511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_accuracy(dec_predicted_data, dec_output_data):\n",
    "    # Here, we have to pass the arguments in the shape (batch_size, sequence_length,classes)\n",
    "    dec_predicted_data = torch.argmax(dec_predicted_data, dim=-1)\n",
    "    dec_output_data = torch.argmax(dec_output_data, dim=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        match = (dec_predicted_data == dec_output_data).all(dim=1)\n",
    "        true_words = match.sum().item()\n",
    "        batch_size = dec_predicted_data.shape[0]\n",
    "    \n",
    "    accuracy = (true_words / batch_size) * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e1a52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_acc=calculate_word_accuracy(decoder_input_data,decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd3abf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(word_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1428344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_char_accuracy(decoder_predicted_data, decoder_output_data):\n",
    "    #Here, we have to pass the arguments in the shape(batch_size,sequence_length,unique_tokens)\n",
    "    batch_size, seq_length,unique_tokens = decoder_predicted_data.shape\n",
    "    dec_predicted_data=torch.argmax(decoder_predicted_data,dim=-1)\n",
    "    dec_output_data=torch.argmax(decoder_output_data,dim=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_count = (dec_predicted_data == dec_output_data).sum().item()\n",
    "        return (correct_count / (seq_length * batch_size))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01bdebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_accuracy = calculate_char_accuracy(decoder_input_data[7:9,:,:],decoder_input_data[1:3,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a66732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.36363636363637\n"
     ]
    }
   ],
   "source": [
    "print(char_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e9e3285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ea2b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens_eng=len(english_vocab)\n",
    "unique_tokens_hin=len(hindi_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e331c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1287bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(x,y,z,batch_size,device=device):\n",
    "    \n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    z=z.to(device)\n",
    "    combined=TensorDataset(x,y,z)\n",
    "    loader=DataLoader(combined,batch_size=batch_size,shuffle=False,drop_last=True)#required in test data\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07817af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34451/3367549510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_tokens_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'''unique_token_hin is the third dimension in one hot encoding or no of tokens in eng or input size'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_dim, drop_out, bi_dir, cell,unique_tokens_eng):\n",
    "        '''unique_token_hin is the third dimension in one hot encoding or no of tokens in eng or input size'''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.unique_tokens_eng=unique_tokens_eng\n",
    "        self.embed_dim=embed_dim\n",
    "        self.drop_out=drop_out\n",
    "        '''The input to the encoder will be of shape (batch_size,sequence_length) and the output size will be\n",
    "        (batch_size,seq_length,embed_size)'''\n",
    "        self.drop__out=nn.Dropout(p=self.drop_out)\n",
    "\n",
    "        self.embedding = nn.Embedding(unique_tokens_eng, embed_dim) \n",
    "        #self.relu=nn.ReLU()\n",
    "        self.rnn=nn.RNN(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.gru=nn.GRU(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.lstm=nn.LSTM(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                         num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.linear =nn.Linear(self.hidden_dim*(1+int(self.bi_dir)),self.hidden_dim)\n",
    "\n",
    "    def forward(self, x,hidden):\n",
    "        '''Here, x is the encoder input data'''\n",
    "        batch_size=x.size(0)\n",
    "        embedding_input = self.embedding(x)\n",
    "        #embedding_input = self.drop__out(embedding_input)\n",
    "        embedding_input = self.relu(embedding_input)\n",
    "        embedding_input=embedding_input.to(device)\n",
    "        if self.cell==\"GRU\":\n",
    "            output,h_n=self.gru(embedding_input,hidden)\n",
    "            return output,h_n\n",
    "        elif self.cell=='RNN':\n",
    "            output,h_n=self.gru(embedding_input,hidden)\n",
    "            return output,h_n\n",
    "        elif self.cell=='LSTM':\n",
    "            output,(h_n,c_n)=self.lstm(embedding_input,hidden)\n",
    "            return output,(h_n,c_n)\n",
    "        \n",
    "    def encoder_initial(self,batch_size,device=device):\n",
    "        if self.cell == \"LSTM\":\n",
    "            h_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            c_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device) \n",
    "            return (h_0,c_0)\n",
    "        #H_0,C_0 HAVE SAME DIMENSION\n",
    "        else:\n",
    "            h_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            return h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f55ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, layer_dim, drop_out, bi_dir, cell,unique_tokens_hin):\n",
    "        '''unique_token_hin is the third dimension in one hot encoding or no of tokens in hindi or output size'''\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.unique_tokens_hin=unique_tokens_hin\n",
    "        self.embed_dim=embed_dim\n",
    "        self.drop_out=drop_out\n",
    "        '''The input to the embedding will be of shape (batch_size,sequence_length) and the output size will be\n",
    "        (batch_size,seq_length,embed_size)'''\n",
    "\n",
    "        self.embedding = nn.Embedding(unique_tokens_hin, embed_dim) \n",
    "        self.drop__out=nn.Dropout(p=self.drop_out)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.rnn=nn.RNN(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.gru=nn.GRU(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                        num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.lstm=nn.LSTM(embed_dim,hidden_dim,dropout=self.drop_out,\n",
    "                         num_layers=layer_dim,bidirectional=bi_dir,batch_first=True)\n",
    "        self.out_put = nn.Linear((1 + int(self.bi_dir)) * self.hidden_dim, self.unique_tokens_hin)\n",
    "        #number of unique tokens in hindi is the output dimension of decoder layer\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x,hidden):\n",
    "        '''Here, x is the decoder input data'''\n",
    "        batch_size=x.size(0)\n",
    "        embedding_output = self.embedding(x.long())\n",
    "        embedding_output=embedding_output.to(device)\n",
    "        #embedding_output = self.drop__out(embedding_output)\n",
    "        if self.cell==\"GRU\":\n",
    "            hidden=hidden.contiguous()\n",
    "            output,h_n=self.gru(embedding_output,hidden)\n",
    "            output=self.relu(output)\n",
    "            output=self.softmax(self.out_put(output))\n",
    "            return output,h_n\n",
    "        elif self.cell=='RNN':\n",
    "            output,h_n=self.gru(embedding_output,hidden)\n",
    "            output=self.relu(output)\n",
    "            output=self.softmax(self.out_put(output))\n",
    "            return output,h_n\n",
    "        elif self.cell=='LSTM':\n",
    "            h0=hidden[0].contiguous()\n",
    "            c0=hidden[1].contiguous()\n",
    "            output,(h_n,c_n)=self.lstm(embedding_output,(h0,c0))\n",
    "            output=self.relu(output)\n",
    "            output=self.softmax(self.out_put(output))\n",
    "            return output,(h_n,c_n)\n",
    "            \n",
    "    def decoder_initial(self,batch_size,device=device):\n",
    "        if self.cell == \"LSTM\":\n",
    "            h_0 =torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            c_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device) \n",
    "            return (h_0,c_0)\n",
    "          #H_0,C_0 HAVE SAME DIMENSION\n",
    "        else:\n",
    "            h_0=torch.randn((1 + int(self.bi_dir)) * self.layer_dim, batch_size, self.hidden_dim, device=device)\n",
    "            return h_0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ce055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To use when the number of encoder and decoder layers are different'''\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, num_enc_layers, num_dec_layers, cell, bi_dir):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.num_enc_layers = num_enc_layers\n",
    "        self.num_dec_layers = num_dec_layers\n",
    "        self.cell = cell\n",
    "        self.bi_dir = bi_dir\n",
    "        self.linear = nn.Linear(num_enc_layers * int(1 + bi_dir), num_dec_layers * int(1 + bi_dir))\n",
    "\n",
    "    def forward(self, h_n_enc):\n",
    "        if self.cell == 'LSTM':\n",
    "            x=x.permute(*torch.arange(x.ndim - 1, -1, -1))\n",
    "            h_dec = self.linear(h_n_enc[0].permute(*torch.arange(h_n_enc.ndim - 1, -1, -1)))\n",
    "            c_dec = self.linear(h_n_enc[1].permute(*torch.arange(c_n_enc.ndim - 1, -1, -1)))\n",
    "            h_0_dec = (h_dec.permute(*torch.arange(h_dec.ndim - 1, -1, -1)),\n",
    "                       c_dec.permute(*torch.arange(c_dec.ndim - 1, -1, -1)))\n",
    "        else:\n",
    "            h_0_dec = self.linear(h_n_enc.permute(*torch.arange(h_n_enc.ndim - 1, -1, -1)))\n",
    "            h_0_dec = h_0_dec.permute(*torch.arange(h_0_dec.ndim - 1, -1, -1))\n",
    "        return h_0_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e8fbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(input_tensor, target_tensor,target_onehot, encoder_model, decoder_model, encoder_optimizer,\n",
    "          decoder_optimizer,hidden_dim,criterion,input_length,target_length,batch_size,\n",
    "             teacher_forcing_ratio,num_enc_layers,num_dec_layers,bi_dir,cell,reshape,ropt,device=device):\n",
    "    \n",
    "    \n",
    "    h_0_enc = encoder_model.encoder_initial(batch_size)\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #ropt.zero_grad()\n",
    "    uh=target_onehot.shape[-1]\n",
    "    decoder_predicted=torch.zeros(batch_size,target_length,uh,device=device)\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_model.train()\n",
    "    decoder_model.train()\n",
    "    #reshape.train()\n",
    "    \n",
    "    '''Encoder model is given and the representation of input word is taken from it'''\n",
    "    for i in range(input_length):\n",
    "        output_enc, h_n_enc = encoder_model(input_tensor[:,i].unsqueeze(1), h_0_enc)\n",
    "        h_0_enc=h_n_enc\n",
    "\n",
    "    dec_input = torch.ones(batch_size,1,device=device)#start token is given as the input and the indices is 1.\n",
    "    #h_0_dec=reshape(h_n_enc)\n",
    "    h_0_dec=h_n_enc\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(target_length):\n",
    "            output_dec, h_n_dec = decoder_model(dec_input, h_0_dec)\n",
    "            decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "            loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "            #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "            dec_input = target_tensor[:,i].unsqueeze(1)  # Teacher forcing\n",
    "            h_0_dec = h_n_dec\n",
    "            \n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(target_length):\n",
    "            output_dec, h_n_dec = decoder_model(dec_input, h_0_dec)\n",
    "            #top_values, top_indices = output_dec.topk(k=1, dim=2)\n",
    "            #dec_input = top_indices.view(-1,1).detach()# detach from history as input\n",
    "            dec_input = torch.argmax(output_dec,dim=-1)\n",
    "            decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "            loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "            #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "            h_0_dec=h_n_dec\n",
    "    \n",
    "            \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #ropt.step()\n",
    "    \n",
    "    loss_batch = loss.item() / target_length\n",
    "    char_acc_batch = calculate_char_accuracy(decoder_predicted,target_onehot)\n",
    "    word_acc_batch = calculate_word_accuracy(decoder_predicted,target_onehot)\n",
    "    return loss_batch, char_acc_batch, word_acc_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "239ffb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(input_tensor, target_tensor,target_onehot, encoder_model, decoder_model,\n",
    "          hidden_dim,criterion,input_length,target_length,batch_size,\n",
    "             num_enc_layers,num_dec_layers,bi_dir,cell,reshape,device=device):\n",
    "    \n",
    "    \n",
    "    h_0_enc = encoder_model.encoder_initial(batch_size)\n",
    "    uh=target_onehot.shape[-1]\n",
    "    decoder_predicted=torch.zeros(batch_size,target_length,uh,device=device)\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_model.eval()\n",
    "    decoder_model.eval()\n",
    "    #reshape.eval()\n",
    "    \n",
    "    '''Encoder model is given and the representation of input word is taken from it'''\n",
    "    for i in range(input_length):\n",
    "        output_enc, h_n_enc = encoder_model(input_tensor[:,i].unsqueeze(1), h_0_enc)\n",
    "        h_0_enc=h_n_enc\n",
    "\n",
    "    dec_input = torch.ones(batch_size,1,device=device)#start token is given as the input and the indices is 1.\n",
    "    #h_0_dec=reshape(h_n_enc)\n",
    "    h_0_dec=h_n_enc\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for i in range(target_length):\n",
    "        output_dec, h_n_dec = decoder_model(dec_input, h_0_dec)\n",
    "        #top_values, top_indices = output_dec.topk(k=1, dim=2)\n",
    "        #dec_input = top_indices.view(-1,1).detach()# detach from history as input\n",
    "        dec_input = torch.argmax(output_dec,dim=-1)\n",
    "        decoder_predicted[:, i, :] = output_dec.squeeze(1)\n",
    "        h_0_dec=h_n_dec\n",
    "        loss += criterion(output_dec.reshape(-1,uh).float(), target_onehot[:,i:i+1,:].reshape(-1,uh).float())\n",
    "        #loss+=criterion(output_dec.view(-1,uh).float(),target_tensor[:,i].long())\n",
    "    \n",
    "    loss_batch = loss.item() / target_length\n",
    "    char_acc_batch = calculate_char_accuracy(decoder_predicted,target_onehot)\n",
    "    word_acc_batch = calculate_word_accuracy(decoder_predicted,target_onehot)\n",
    "    return loss_batch, char_acc_batch, word_acc_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44469cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x=enc_input_data,y=dec_output_data,yonehot=decoder_output_data,\n",
    "          x_val=enc_input_data_val,y_val=dec_output_data_val,yonehot_val=decoder_output_data_val,\n",
    "          epochs=10,optimizer='Adam',learning_rate=0.001,weight_decay=0.001,layer_dim=2,bi_dir=True,\n",
    "          teacher_forcing_ratio=0.5,cell='GRU',embed_dim=256,hidden_dim=256,batch_size=64,drop_out=0.3):\n",
    "    \n",
    "    start = time.time()\n",
    "    input_length = x.shape[1]\n",
    "    target_length = y.shape[1]\n",
    "    num_enc_layers=layer_dim\n",
    "    num_dec_layers=layer_dim\n",
    "    \n",
    "    encoder_model = Encoder(embed_dim, hidden_dim, num_enc_layers, drop_out, bi_dir, cell,unique_tokens_eng).to(device)\n",
    "    decoder_model = Decoder(embed_dim, hidden_dim, num_dec_layers, drop_out, bi_dir, cell,unique_tokens_hin).to(device)\n",
    "    reshape=Reshape(num_enc_layers, num_dec_layers, cell, bi_dir).to(device)\n",
    "    \n",
    "    if optimizer=='Adam':\n",
    "        encoder_optimizer=torch.optim.Adam(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.Adam(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.Adam(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    elif optimizer=='NAdam':\n",
    "        encoder_optimizer=torch.optim.NAdam(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.NAdam(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.NAdam(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    elif optimizer=='SGD':\n",
    "        \n",
    "        encoder_optimizer=torch.optim.SGD(encoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        decoder_optimizer=torch.optim.SGD(decoder_model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        ropt = torch.optim.SGD(reshape.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "        \n",
    "    train_loader = data_loader(x,y,yonehot,batch_size,device=device)\n",
    "    val_loader = data_loader(x_val,y_val,yonehot_val,batch_size,device=device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion=nn.NLLLoss()\n",
    "    \n",
    "    epoch_losses=[]\n",
    "    epoch_char_accuracy=[]\n",
    "    epoch_word_accuracy=[]\n",
    "    epoch_losses_val=[]\n",
    "    epoch_char_accuracy_val=[]\n",
    "    epoch_word_accuracy_val=[]\n",
    "    \n",
    "    for i in range(1, epochs + 1):\n",
    "        batch_losses=[]\n",
    "        batch_char_acc=[]\n",
    "        batch_word_acc=[]\n",
    "        batch_losses_val=[]\n",
    "        batch_char_acc_val=[]\n",
    "        batch_word_acc_val=[]\n",
    "        for enc_input_tensor,dec_target_tensor,dec_onehot in train_loader:\n",
    "            \n",
    "            loss_batch,char_acc_batch,word_acc_batch = gradient(enc_input_tensor,dec_target_tensor,dec_onehot,\n",
    "                    encoder_model,decoder_model,encoder_optimizer,decoder_optimizer,\n",
    "                    hidden_dim,criterion,input_length,target_length,batch_size, teacher_forcing_ratio,\n",
    "                            num_enc_layers,num_dec_layers,bi_dir,cell,reshape,ropt,device=device)\n",
    "            \n",
    "        for enc_input_tensor_val,dec_target_tensor_val,dec_onehot_val in val_loader: \n",
    "            \n",
    "            loss_batch_val,char_acc_batch_val,word_acc_batch_val=testing(enc_input_tensor_val,dec_target_tensor_val,\n",
    "                        dec_onehot_val,encoder_model,decoder_model,hidden_dim,criterion,input_length,\n",
    "                        target_length,batch_size,num_enc_layers,num_dec_layers,bi_dir,cell,reshape,device=device)\n",
    "          \n",
    "            batch_losses.append(loss_batch)\n",
    "            batch_char_acc.append(char_acc_batch)\n",
    "            batch_word_acc.append(word_acc_batch)\n",
    "            batch_losses_val.append(loss_batch_val)\n",
    "            batch_char_acc_val.append(char_acc_batch_val)\n",
    "            batch_word_acc_val.append(word_acc_batch_val)\n",
    "            \n",
    "            \n",
    "        epoch_loss=sum(batch_losses)/len(batch_losses)\n",
    "        epoch_char_acc=sum(batch_char_acc)/len(batch_char_acc)\n",
    "        epoch_word_acc=sum(batch_word_acc)/len(batch_word_acc)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_char_accuracy.append(epoch_char_acc)\n",
    "        epoch_word_accuracy.append(epoch_word_acc)\n",
    "        \n",
    "        epoch_loss_val = sum(batch_losses_val) / len(batch_losses_val)\n",
    "        epoch_char_acc_val = sum(batch_char_acc_val) / len(batch_char_acc_val)\n",
    "        epoch_word_acc_val = sum(batch_word_acc_val) / len(batch_word_acc_val)\n",
    "        epoch_losses_val.append(epoch_loss_val)\n",
    "        epoch_char_accuracy_val.append(epoch_char_acc_val)\n",
    "        epoch_word_accuracy_val.append(epoch_word_acc_val)\n",
    "        \n",
    "        wandb.log({'train_loss': epoch_loss, 'train_char_acc': epoch_char_acc, 'train_word_acc': epoch_word_acc, 'valid_loss': epoch_loss_val, 'valid_char_acc': epoch_char_acc_val, 'valid_word_acc': epoch_word_acc_val})\n",
    "        print(f'{timeSince(start, i / epochs)} ({i} {i / epochs * 100:.2f}%) Trainloss: {epoch_losses[-1]:.4f} Char Accuracy: {epoch_char_accuracy[-1]:.4f} Word Accuracy: {epoch_word_accuracy[-1]:.4f}')\n",
    "        print(f'{timeSince(start, i / epochs)} ({i} {i / epochs * 100:.2f}%) Validationloss: {epoch_losses_val[-1]:.4f} Char Accuracy: {epoch_char_accuracy_val[-1]:.4f} Word Accuracy: {epoch_word_accuracy_val[-1]:.4f}')\n",
    "\n",
    "\n",
    "    return encoder_model,decoder_model,encoder_optimizer,decoder_optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8888d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_model,decoder_model,encoder_optimizer,decoder_optimizer=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23e583c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample wandb run()\n",
    "def wandb_run():\n",
    "    \n",
    "    config_defaults = {\n",
    "        'optimizer': 'Adam',\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 10,\n",
    "        'hidden_dim': 512,\n",
    "        'embed_dim': 512,\n",
    "        'layer_dim': 2,\n",
    "        'drop_out': 0.3,\n",
    "        'cell': 'GRU',\n",
    "        'weight_decay': 0.001,\n",
    "        'bi_dir': True,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    run_name = f'lr_{config.learning_rate}_acti_{config.optimizer}_epochs_{config.epochs}_cell_{config.cell}_dir_{config.bi_dir}_num_hid_{config.hidden_dim}_ld_{config.layer_dim}_ed_{config.embed_dim}__drop__{config.drop_out}'\n",
    "    print(run_name)\n",
    "    wandb.init(name=run_name)\n",
    "    encoder_model, decoder_model, encoder_optimizer, decoder_optimizer = train(\n",
    "        x=enc_input_data,\n",
    "        y=dec_output_data,\n",
    "        yonehot=decoder_output_data,\n",
    "        x_val=enc_input_data_val,\n",
    "        y_val=dec_output_data_val,\n",
    "        yonehot_val=decoder_output_data_val,\n",
    "        epochs=config.epochs,\n",
    "        optimizer=config.optimizer,\n",
    "        learning_rate=config.learning_rate,\n",
    "        weight_decay=config.weight_decay,\n",
    "        layer_dim=config.layer_dim,\n",
    "        bi_dir=config.bi_dir,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        cell=config.cell,\n",
    "        embed_dim=config.embed_dim,\n",
    "        hidden_dim=config.hidden_dim,\n",
    "        batch_size=config.batch_size,\n",
    "        drop_out=config.drop_out\n",
    "    )\n",
    "     \n",
    "    wandb.run.name = run_name\n",
    "    wandb.run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5e25dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep configuration for wandb\n",
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {\n",
    "        'name': 'valid_word_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'optimizer': {\n",
    "            'values': ['Adam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001, 0.005, 0.01]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [5, 10]\n",
    "        },\n",
    "        'hidden_dim': {\n",
    "            'values': [128,256,512]\n",
    "        },\n",
    "        'layer_dim': {\n",
    "            'values': [1,2]\n",
    "        },\n",
    "        'embed_dim': {\n",
    "            'values': [128,256,512]\n",
    "        },\n",
    "        'drop_out': {\n",
    "            'values': [0, 0.1, 0.2,0.3]\n",
    "        },\n",
    "        'cell': {\n",
    "            'values': [ 'LSTM', 'GRU']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64,128]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0.0001]\n",
    "        },\n",
    "        'bi_dir': {\n",
    "            'values': [True, False]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='CS6910-ASSIGNMENT_3')\n",
    "wandb.agent(sweep_id, function=wandb_run, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b986f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: osakvjph\n",
      "Sweep URL: https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e9wvd14j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_120433-e9wvd14j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">copper-sweep-1</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:e9wvd14j) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda01f7a70d845ce8198cb5c3282ebe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-1</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_120433-e9wvd14j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:e9wvd14j). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc198cb10124e15a6405f0c98f4edf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666935993343941, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_120440-e9wvd14j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 35s (- 5m 16s) (1 10.00%) Trainloss: 0.6450 Char Accuracy: 83.0256 Word Accuracy: 4.6875\n",
      "0m 35s (- 5m 16s) (1 10.00%) Validationloss: 0.8097 Char Accuracy: 77.4936 Word Accuracy: 2.3438\n",
      "1m 9s (- 4m 36s) (2 20.00%) Trainloss: 0.3532 Char Accuracy: 89.4886 Word Accuracy: 14.0625\n",
      "1m 9s (- 4m 36s) (2 20.00%) Validationloss: 0.5391 Char Accuracy: 83.6060 Word Accuracy: 17.7490\n",
      "1m 43s (- 4m 0s) (3 30.00%) Trainloss: 0.5650 Char Accuracy: 82.1023 Word Accuracy: 20.3125\n",
      "1m 43s (- 4m 0s) (3 30.00%) Validationloss: 0.4498 Char Accuracy: 85.5524 Word Accuracy: 23.8770\n",
      "2m 31s (- 3m 47s) (4 40.00%) Trainloss: 0.4804 Char Accuracy: 83.7358 Word Accuracy: 23.4375\n",
      "2m 31s (- 3m 47s) (4 40.00%) Validationloss: 0.4204 Char Accuracy: 86.4935 Word Accuracy: 27.3926\n",
      "3m 20s (- 3m 20s) (5 50.00%) Trainloss: 0.2139 Char Accuracy: 94.1051 Word Accuracy: 29.6875\n",
      "3m 20s (- 3m 20s) (5 50.00%) Validationloss: 0.4203 Char Accuracy: 87.0006 Word Accuracy: 31.3965\n",
      "4m 10s (- 2m 47s) (6 60.00%) Trainloss: 0.2001 Char Accuracy: 95.0994 Word Accuracy: 28.1250\n",
      "4m 10s (- 2m 47s) (6 60.00%) Validationloss: 0.4020 Char Accuracy: 87.2814 Word Accuracy: 31.8115\n",
      "5m 1s (- 2m 9s) (7 70.00%) Trainloss: 0.1798 Char Accuracy: 95.5256 Word Accuracy: 40.6250\n",
      "5m 1s (- 2m 9s) (7 70.00%) Validationloss: 0.4010 Char Accuracy: 87.7253 Word Accuracy: 34.0820\n",
      "5m 50s (- 1m 27s) (8 80.00%) Trainloss: 0.4002 Char Accuracy: 88.2102 Word Accuracy: 40.6250\n",
      "5m 50s (- 1m 27s) (8 80.00%) Validationloss: 0.3981 Char Accuracy: 88.2280 Word Accuracy: 35.6689\n",
      "6m 40s (- 0m 44s) (9 90.00%) Trainloss: 0.3959 Char Accuracy: 87.7131 Word Accuracy: 40.6250\n",
      "6m 40s (- 0m 44s) (9 90.00%) Validationloss: 0.3872 Char Accuracy: 88.2224 Word Accuracy: 35.4980\n",
      "7m 30s (- 0m 0s) (10 100.00%) Trainloss: 0.1574 Char Accuracy: 96.0938 Word Accuracy: 40.6250\n",
      "7m 30s (- 0m 0s) (10 100.00%) Validationloss: 0.3816 Char Accuracy: 88.4588 Word Accuracy: 36.2305\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a5b56d6e5d4c509ea00389a82ff08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>▁▅▁▂▇██▄▄█</td></tr><tr><td>train_loss</td><td>█▄▇▆▂▂▁▄▄▁</td></tr><tr><td>train_word_acc</td><td>▁▃▄▅▆▆████</td></tr><tr><td>valid_char_acc</td><td>▁▅▆▇▇▇████</td></tr><tr><td>valid_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>valid_word_acc</td><td>▁▄▅▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>96.09375</td></tr><tr><td>train_loss</td><td>0.15743</td></tr><tr><td>train_word_acc</td><td>40.625</td></tr><tr><td>valid_char_acc</td><td>88.45881</td></tr><tr><td>valid_loss</td><td>0.38164</td></tr><tr><td>valid_word_acc</td><td>36.23047</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/e9wvd14j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_120440-e9wvd14j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y4ju9vxx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_122824-y4ju9vxx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">rose-sweep-2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:y4ju9vxx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_122824-y4ju9vxx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:y4ju9vxx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_122831-y4ju9vxx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 33s (- 5m 3s) (1 10.00%) Trainloss: 0.9410 Char Accuracy: 72.8693 Word Accuracy: 0.0000\n",
      "0m 33s (- 5m 3s) (1 10.00%) Validationloss: 1.1492 Char Accuracy: 69.7931 Word Accuracy: 0.0244\n",
      "1m 6s (- 4m 27s) (2 20.00%) Trainloss: 0.7117 Char Accuracy: 79.9006 Word Accuracy: 0.0000\n",
      "1m 6s (- 4m 27s) (2 20.00%) Validationloss: 0.9291 Char Accuracy: 74.4962 Word Accuracy: 0.1465\n",
      "1m 39s (- 3m 53s) (3 30.00%) Trainloss: 0.9755 Char Accuracy: 71.6619 Word Accuracy: 1.5625\n",
      "1m 39s (- 3m 53s) (3 30.00%) Validationloss: 0.8045 Char Accuracy: 76.7978 Word Accuracy: 2.3682\n",
      "2m 13s (- 3m 19s) (4 40.00%) Trainloss: 0.5317 Char Accuracy: 84.5881 Word Accuracy: 1.5625\n",
      "2m 13s (- 3m 19s) (4 40.00%) Validationloss: 0.6960 Char Accuracy: 79.3146 Word Accuracy: 5.3467\n",
      "2m 45s (- 2m 45s) (5 50.00%) Trainloss: 0.7907 Char Accuracy: 76.5625 Word Accuracy: 3.1250\n",
      "2m 45s (- 2m 45s) (5 50.00%) Validationloss: 0.6401 Char Accuracy: 80.2535 Word Accuracy: 7.8857\n",
      "3m 18s (- 2m 12s) (6 60.00%) Trainloss: 0.7035 Char Accuracy: 78.5511 Word Accuracy: 10.9375\n",
      "3m 18s (- 2m 12s) (6 60.00%) Validationloss: 0.6022 Char Accuracy: 81.4620 Word Accuracy: 11.1816\n",
      "3m 52s (- 1m 39s) (7 70.00%) Trainloss: 0.3830 Char Accuracy: 88.5653 Word Accuracy: 7.8125\n",
      "3m 52s (- 1m 39s) (7 70.00%) Validationloss: 0.5872 Char Accuracy: 81.8703 Word Accuracy: 13.5742\n",
      "4m 25s (- 1m 6s) (8 80.00%) Trainloss: 0.6981 Char Accuracy: 77.9830 Word Accuracy: 6.2500\n",
      "4m 25s (- 1m 6s) (8 80.00%) Validationloss: 0.5530 Char Accuracy: 82.4396 Word Accuracy: 14.3311\n",
      "4m 58s (- 0m 33s) (9 90.00%) Trainloss: 0.6336 Char Accuracy: 80.1847 Word Accuracy: 9.3750\n",
      "4m 58s (- 0m 33s) (9 90.00%) Validationloss: 0.5470 Char Accuracy: 82.6915 Word Accuracy: 15.5762\n",
      "5m 32s (- 0m 0s) (10 100.00%) Trainloss: 0.3297 Char Accuracy: 90.1278 Word Accuracy: 14.0625\n",
      "5m 32s (- 0m 0s) (10 100.00%) Validationloss: 0.5400 Char Accuracy: 83.2253 Word Accuracy: 18.3350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69cdcfeeb8e439b8d0685d5c02b004d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>▁▄▁▆▃▄▇▃▄█</td></tr><tr><td>train_loss</td><td>█▅█▃▆▅▂▅▄▁</td></tr><tr><td>train_word_acc</td><td>▁▁▂▂▃▆▅▄▆█</td></tr><tr><td>valid_char_acc</td><td>▁▃▅▆▆▇▇███</td></tr><tr><td>valid_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>valid_word_acc</td><td>▁▁▂▃▄▅▆▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>90.12784</td></tr><tr><td>train_loss</td><td>0.32971</td></tr><tr><td>train_word_acc</td><td>14.0625</td></tr><tr><td>valid_char_acc</td><td>83.22532</td></tr><tr><td>valid_loss</td><td>0.53995</td></tr><tr><td>valid_word_acc</td><td>18.33496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_2_ed_256__drop__0.2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/y4ju9vxx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_122831-y4ju9vxx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3tvkbksh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_125020-3tvkbksh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">logical-sweep-3</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_3_ed_256__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3tvkbksh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98d895bcc8f4269b2c7810b835c74a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-3</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_125020-3tvkbksh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3tvkbksh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_125026-3tvkbksh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_3_ed_256__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 41s (- 6m 11s) (1 10.00%) Trainloss: 0.9489 Char Accuracy: 73.2955 Word Accuracy: 0.0000\n",
      "0m 41s (- 6m 11s) (1 10.00%) Validationloss: 1.0542 Char Accuracy: 71.7596 Word Accuracy: 0.0000\n",
      "1m 22s (- 5m 30s) (2 20.00%) Trainloss: 0.7711 Char Accuracy: 76.9886 Word Accuracy: 10.9375\n",
      "1m 22s (- 5m 30s) (2 20.00%) Validationloss: 0.5719 Char Accuracy: 82.7015 Word Accuracy: 13.6230\n",
      "2m 3s (- 4m 48s) (3 30.00%) Trainloss: 0.6507 Char Accuracy: 79.9006 Word Accuracy: 15.6250\n",
      "2m 3s (- 4m 48s) (3 30.00%) Validationloss: 0.4647 Char Accuracy: 85.5657 Word Accuracy: 25.0488\n",
      "2m 44s (- 4m 6s) (4 40.00%) Trainloss: 0.5720 Char Accuracy: 80.8949 Word Accuracy: 21.8750\n",
      "2m 44s (- 4m 6s) (4 40.00%) Validationloss: 0.4255 Char Accuracy: 86.9196 Word Accuracy: 30.3223\n",
      "3m 25s (- 3m 25s) (5 50.00%) Trainloss: 0.4802 Char Accuracy: 84.8722 Word Accuracy: 26.5625\n",
      "3m 25s (- 3m 25s) (5 50.00%) Validationloss: 0.4108 Char Accuracy: 87.4967 Word Accuracy: 33.0566\n",
      "4m 6s (- 2m 44s) (6 60.00%) Trainloss: 0.1868 Char Accuracy: 94.9574 Word Accuracy: 31.2500\n",
      "4m 6s (- 2m 44s) (6 60.00%) Validationloss: 0.3914 Char Accuracy: 88.0826 Word Accuracy: 34.9121\n",
      "4m 47s (- 2m 3s) (7 70.00%) Trainloss: 0.4434 Char Accuracy: 84.8722 Word Accuracy: 26.5625\n",
      "4m 47s (- 2m 3s) (7 70.00%) Validationloss: 0.3821 Char Accuracy: 88.0438 Word Accuracy: 34.9121\n",
      "5m 28s (- 1m 22s) (8 80.00%) Trainloss: 0.1472 Char Accuracy: 96.2358 Word Accuracy: 50.0000\n",
      "5m 28s (- 1m 22s) (8 80.00%) Validationloss: 0.3908 Char Accuracy: 88.5764 Word Accuracy: 37.2559\n",
      "6m 7s (- 0m 40s) (9 90.00%) Trainloss: 0.1479 Char Accuracy: 96.0938 Word Accuracy: 50.0000\n",
      "6m 7s (- 0m 40s) (9 90.00%) Validationloss: 0.3913 Char Accuracy: 88.5454 Word Accuracy: 36.4014\n",
      "6m 47s (- 0m 0s) (10 100.00%) Trainloss: 0.1333 Char Accuracy: 96.5199 Word Accuracy: 48.4375\n",
      "6m 47s (- 0m 0s) (10 100.00%) Validationloss: 0.3814 Char Accuracy: 88.7329 Word Accuracy: 37.0117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>▁▂▃▃▄█▄███</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▁▄▁▁▁</td></tr><tr><td>train_word_acc</td><td>▁▃▃▄▅▅▅███</td></tr><tr><td>valid_char_acc</td><td>▁▆▇▇▇█████</td></tr><tr><td>valid_loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr><tr><td>valid_word_acc</td><td>▁▄▆▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_char_acc</td><td>96.51989</td></tr><tr><td>train_loss</td><td>0.13329</td></tr><tr><td>train_word_acc</td><td>48.4375</td></tr><tr><td>valid_char_acc</td><td>88.73291</td></tr><tr><td>valid_loss</td><td>0.38145</td></tr><tr><td>valid_word_acc</td><td>37.01172</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lr_0.001_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_3_ed_256__drop__0.2</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/3tvkbksh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_125026-3tvkbksh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jlyzbsbk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_dir: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_out: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_dim: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: NAdam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_131333-jlyzbsbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk' target=\"_blank\">hearty-sweep-4</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_3_ed_256__drop__0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jlyzbsbk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-4</strong> at: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230528_131333-jlyzbsbk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jlyzbsbk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agcl/Downloads/wandb/run-20230528_131340-jlyzbsbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk' target=\"_blank\">lr_0.005_acti_NAdam_epochs_10_cell_LSTM_dir_True_num_hid_256_ld_3_ed_256__drop__0.2</a></strong> to <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/sweeps/osakvjph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk' target=\"_blank\">https://wandb.ai/ananthu2014/CS6910-ASSIGNMENT_3/runs/jlyzbsbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 40s (- 6m 5s) (1 10.00%) Trainloss: 0.9584 Char Accuracy: 72.8693 Word Accuracy: 0.0000\n",
      "0m 40s (- 6m 5s) (1 10.00%) Validationloss: 1.1318 Char Accuracy: 69.4325 Word Accuracy: 0.0000\n",
      "1m 21s (- 5m 26s) (2 20.00%) Trainloss: 0.6098 Char Accuracy: 82.1733 Word Accuracy: 0.0000\n",
      "1m 21s (- 5m 26s) (2 20.00%) Validationloss: 0.6702 Char Accuracy: 80.0659 Word Accuracy: 5.5176\n",
      "2m 2s (- 4m 46s) (3 30.00%) Trainloss: 0.4286 Char Accuracy: 86.8608 Word Accuracy: 6.2500\n",
      "2m 2s (- 4m 46s) (3 30.00%) Validationloss: 0.5490 Char Accuracy: 82.9923 Word Accuracy: 14.9902\n",
      "2m 43s (- 4m 5s) (4 40.00%) Trainloss: 0.6428 Char Accuracy: 79.9716 Word Accuracy: 12.5000\n",
      "2m 43s (- 4m 5s) (4 40.00%) Validationloss: 0.5194 Char Accuracy: 83.9256 Word Accuracy: 19.1162\n",
      "3m 24s (- 3m 24s) (5 50.00%) Trainloss: 0.3337 Char Accuracy: 90.7670 Word Accuracy: 15.6250\n",
      "3m 24s (- 3m 24s) (5 50.00%) Validationloss: 0.4867 Char Accuracy: 84.7823 Word Accuracy: 21.9238\n",
      "4m 6s (- 2m 44s) (6 60.00%) Trainloss: 0.2878 Char Accuracy: 91.4773 Word Accuracy: 17.1875\n",
      "4m 6s (- 2m 44s) (6 60.00%) Validationloss: 0.4930 Char Accuracy: 85.1263 Word Accuracy: 23.1201\n",
      "4m 46s (- 2m 2s) (7 70.00%) Trainloss: 0.5335 Char Accuracy: 83.5938 Word Accuracy: 25.0000\n",
      "4m 46s (- 2m 2s) (7 70.00%) Validationloss: 0.4900 Char Accuracy: 85.1962 Word Accuracy: 24.0967\n",
      "5m 28s (- 1m 22s) (8 80.00%) Trainloss: 0.2800 Char Accuracy: 91.8324 Word Accuracy: 18.7500\n",
      "5m 28s (- 1m 22s) (8 80.00%) Validationloss: 0.4593 Char Accuracy: 85.7122 Word Accuracy: 24.5605\n",
      "6m 9s (- 0m 41s) (9 90.00%) Trainloss: 0.6091 Char Accuracy: 81.5341 Word Accuracy: 21.8750\n",
      "6m 9s (- 0m 41s) (9 90.00%) Validationloss: 0.4740 Char Accuracy: 85.5324 Word Accuracy: 25.6348\n",
      "6m 51s (- 0m 0s) (10 100.00%) Trainloss: 0.2389 Char Accuracy: 92.8267 Word Accuracy: 17.1875\n",
      "6m 51s (- 0m 0s) (10 100.00%) Validationloss: 0.4583 Char Accuracy: 86.2260 Word Accuracy: 27.3926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0113c325e7564ea595ad7163f9252147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "#concentrated sweeps around best valid accuracy\n",
    "sweep_config = {\n",
    "    'method': 'grid', \n",
    "    'metric': {\n",
    "        'name': 'valid_word_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'optimizer': {\n",
    "            'values': ['NAdam']\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.001,0.005]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [10]\n",
    "        },\n",
    "        'hidden_dim': {\n",
    "            'values': [256,512]\n",
    "        },\n",
    "        'layer_dim': {\n",
    "            'values': [2,3]\n",
    "        },\n",
    "        'embed_dim': {\n",
    "            'values': [256]\n",
    "        },\n",
    "        'drop_out': {\n",
    "            'values': [0.2,0.3]\n",
    "        },\n",
    "        'cell': {\n",
    "            'values': [ 'LSTM']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [64]\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0.0]\n",
    "        },\n",
    "        'bi_dir': {\n",
    "            'values': [True]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='CS6910-ASSIGNMENT_3')\n",
    "wandb.agent(sweep_id, function=wandb_run,count=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212054f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
